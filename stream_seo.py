import streamlit as st
import requests
import pandas as pd
import time
import json
import os
from datetime import datetime, timedelta
from io import BytesIO

# ============ é é¢è¨­å®š ============

st.set_page_config(
    page_title="SEO æ’åè¿½è¹¤å·¥å…· Pro",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============ è‡ªè¨‚ CSS ============

st.markdown("""
<style>
    /* ä¸»è¦å®¹å™¨ */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
        text-align: center;
    }

    /* çµ±è¨ˆå¡ç‰‡ */
    .stat-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        text-align: center;
        border-left: 4px solid #667eea;
    }

    .stat-number {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
    }

    .stat-label {
        color: #666;
        font-size: 0.9rem;
    }

    /* æ’åè®ŠåŒ– */
    .rank-up {
        color: #10B981;
        font-weight: bold;
    }

    .rank-down {
        color: #EF4444;
        font-weight: bold;
    }

    .rank-same {
        color: #6B7280;
    }

    /* æ’åå¾½ç«  */
    .rank-badge-top3 {
        background: linear-gradient(135deg, #10B981, #059669);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-weight: bold;
    }

    .rank-badge-top10 {
        background: linear-gradient(135deg, #F59E0B, #D97706);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-weight: bold;
    }

    .rank-badge-top20 {
        background: linear-gradient(135deg, #6B7280, #4B5563);
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-weight: bold;
    }

    .rank-badge-na {
        background: #FEE2E2;
        color: #DC2626;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
    }

    /* å´é‚Šæ¬„ç¾åŒ– */
    .sidebar .sidebar-content {
        background: #f8f9fa;
    }

    /* æŒ‰éˆ•ç¾åŒ– */
    .stButton > button {
        width: 100%;
        border-radius: 10px;
        padding: 0.75rem 1.5rem;
        font-weight: bold;
    }

    /* æ¨™ç±¤é  */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }

    .stTabs [data-baseweb="tab"] {
        border-radius: 10px 10px 0 0;
        padding: 10px 20px;
    }
</style>
""", unsafe_allow_html=True)

# ============ æ•¸æ“šå„²å­˜åŠŸèƒ½ ============

DATA_FILE = "serp_history.json"


def load_history():
    """è¼‰å…¥æ­·å²è¨˜éŒ„"""
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {"records": [], "settings": {}}
    return {"records": [], "settings": {}}


def save_history(data):
    """å„²å­˜æ­·å²è¨˜éŒ„"""
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def add_record(history, record):
    """æ–°å¢è¨˜éŒ„"""
    record["timestamp"] = datetime.now().isoformat()
    record["date"] = datetime.now().strftime("%Y-%m-%d")
    history["records"].append(record)
    save_history(history)
    return history


# ============ åˆå§‹åŒ– Session State ============

if "history" not in st.session_state:
    st.session_state.history = load_history()

if "current_results" not in st.session_state:
    st.session_state.current_results = None

# ============ æ¨™é¡Œ ============

st.markdown("""
<div class="main-header">
    <h1>ğŸš€ SEO æ’åè¿½è¹¤å·¥å…· Pro</h1>
    <p>è¿½è¹¤æ’åè®ŠåŒ– Â· åˆ†æç«¶çˆ­å°æ‰‹ Â· å„ªåŒ– SEO ç­–ç•¥</p>
</div>
""", unsafe_allow_html=True)

# ============ å´é‚Šæ¬„è¨­å®š ============

with st.sidebar:
    st.markdown("## âš™ï¸ è¨­å®š")

    # API Key
    api_key = st.text_input(
        "ğŸ”‘ Serper API Key",
        type="password",
        help="åœ¨ serper.dev è¨»å†Šå–å¾—å…è²» API Key"
    )

    if api_key:
        st.success("âœ… API Key å·²è¨­å®š")
    else:
        st.warning("âš ï¸ è«‹è¼¸å…¥ API Key")

    st.markdown("---")

    # æœå°‹è¨­å®š
    st.markdown("### ğŸ” æœå°‹è¨­å®š")

    col1, col2 = st.columns(2)
    with col1:
        search_region = st.selectbox(
            "åœ°å€",
            options=["hk", "tw", "sg", "my", "us", "uk"],
            format_func=lambda x: {
                "hk": "ğŸ‡­ğŸ‡° é¦™æ¸¯",
                "tw": "ğŸ‡¹ğŸ‡¼ å°ç£",
                "sg": "ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡",
                "my": "ğŸ‡²ğŸ‡¾ é¦¬ä¾†è¥¿äº",
                "us": "ğŸ‡ºğŸ‡¸ ç¾åœ‹",
                "uk": "ğŸ‡¬ğŸ‡§ è‹±åœ‹"
            }[x]
        )

    with col2:
        search_lang = st.selectbox(
            "èªè¨€",
            options=["zh-tw", "zh-cn", "en"],
            format_func=lambda x: {
                "zh-tw": "ç¹é«”ä¸­æ–‡",
                "zh-cn": "ç®€ä½“ä¸­æ–‡",
                "en": "English"
            }[x]
        )

    max_pages = st.slider(
        "ğŸ“„ çˆ¬å–é æ•¸",
        min_value=1,
        max_value=10,
        value=5,
        help="æ¯é  10 å€‹çµæœ"
    )

    st.info(f"æ¯å€‹é—œéµå­—å°‡çˆ¬å– **{max_pages * 10}** å€‹çµæœ")

    st.markdown("---")

    # æˆ‘çš„ç¶²ç«™
    st.markdown("### ğŸ  æˆ‘çš„ç¶²ç«™")
    my_sites_input = st.text_area(
        "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
        value="example.com",
        height=100,
        key="my_sites"
    )
    my_sites = [s.strip() for s in my_sites_input.split("\n") if s.strip()]

    # ç«¶çˆ­å°æ‰‹
    st.markdown("### ğŸ¯ ç«¶çˆ­å°æ‰‹")
    competitors_input = st.text_area(
        "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
        value="competitor1.com\ncompetitor2.com",
        height=100,
        key="competitors"
    )
    competitors = [s.strip() for s in competitors_input.split("\n") if s.strip()]

    st.markdown("---")

    # æ­·å²è¨˜éŒ„çµ±è¨ˆ
    st.markdown("### ğŸ“Š æ•¸æ“šçµ±è¨ˆ")
    total_records = len(st.session_state.history.get("records", []))
    st.metric("ç¸½è¨˜éŒ„æ•¸", total_records)

# ============ ä¸»è¦å€åŸŸ - æ¨™ç±¤é  ============

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” æ’åæŸ¥è©¢", "ğŸ“ˆ æ­·å²è¶¨å‹¢", "ğŸ“Š æ•¸æ“šåˆ†æ", "âš™ï¸ ç®¡ç†"])

# ============ Tab 1: æ’åæŸ¥è©¢ ============

with tab1:
    col_left, col_right = st.columns([2, 1])

    with col_left:
        st.markdown("### ğŸ“ è¼¸å…¥é—œéµå­—")
        keywords_input = st.text_area(
            "æ¯è¡Œä¸€å€‹é—œéµå­—",
            value="åˆ°æœƒ\nåˆ°æœƒæ¨ä»‹\næ´¾å°åˆ°æœƒ",
            height=200,
            key="keywords_input"
        )
        keywords = [k.strip() for k in keywords_input.split("\n") if k.strip()]

    with col_right:
        st.markdown("### ğŸ“‹ å¿«é€ŸåŒ¯å…¥")

        # é—œéµå­—åˆ†çµ„
        keyword_groups = {
            "åˆ°æœƒç›¸é—œ": ["åˆ°æœƒ", "åˆ°æœƒæ¨ä»‹", "åˆ°æœƒæœå‹™", "æ´¾å°åˆ°æœƒ", "å…¬å¸åˆ°æœƒ", "åˆ°æœƒå¤–è³£"],
            "é¤é£²ç›¸é—œ": ["catering", "å¤–è³£", "è¨‚é¤", "å®´æœƒ"],
            "è‡ªè¨‚": []
        }

        selected_group = st.selectbox("é¸æ“‡é—œéµå­—çµ„", list(keyword_groups.keys()))

        if selected_group != "è‡ªè¨‚" and keyword_groups[selected_group]:
            if st.button("ğŸ“¥ åŒ¯å…¥æ­¤çµ„é—œéµå­—"):
                st.session_state.keywords_input = "\n".join(keyword_groups[selected_group])
                st.rerun()

        st.markdown("---")
        st.markdown(f"**å…± {len(keywords)} å€‹é—œéµå­—**")
        st.markdown(f"**é è¨ˆ API èª¿ç”¨ï¼š{len(keywords) * max_pages} æ¬¡**")

    st.markdown("---")

    # åŸ·è¡ŒæŒ‰éˆ•
    col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
    with col_btn2:
        start_tracking = st.button("ğŸš€ é–‹å§‹è¿½è¹¤æ’å", type="primary", use_container_width=True)

    # ============ åŸ·è¡Œæœå°‹ ============

    if start_tracking:
        if not api_key:
            st.error("âŒ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Key")
            st.stop()

        if not keywords:
            st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")
            st.stop()

        all_sites = my_sites + competitors
        if not all_sites:
            st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹è¦è¿½è¹¤çš„ç¶²ç«™")
            st.stop()

        # é€²åº¦é¡¯ç¤º
        progress_container = st.container()
        with progress_container:
            overall_progress = st.progress(0)
            status_text = st.empty()

        all_rankings = []
        all_serp_data = {}


        def search_serp(keyword, page, api_key):
            url = "https://google.serper.dev/search"
            payload = {
                "q": keyword,
                "gl": search_region,
                "hl": search_lang,
                "num": 10,
                "page": page
            }
            headers = {
                "X-API-KEY": api_key,
                "Content-Type": "application/json"
            }
            try:
                response = requests.post(url, headers=headers, json=payload)
                data = response.json()
                return data.get("organic", [])
            except Exception as e:
                st.error(f"API éŒ¯èª¤: {e}")
                return []


        def get_all_results(keyword, max_pages, api_key):
            all_results = []
            for page in range(1, max_pages + 1):
                status_text.text(f"ğŸ” æŸ¥è©¢ã€Œ{keyword}ã€ç¬¬ {page}/{max_pages} é ...")
                results = search_serp(keyword, page, api_key)
                if not results:
                    break
                for result in results:
                    original_position = result.get("position", 0)
                    actual_rank = (page - 1) * 10 + original_position
                    result["actual_rank"] = actual_rank
                    result["page"] = page
                all_results.extend(results)
                time.sleep(0.3)
            return all_results


        def find_ranking(results, domain):
            for result in results:
                link = result.get("link", "")
                if domain in link:
                    return result.get("actual_rank", None)
            return None


        # åŸ·è¡Œæœå°‹
        for i, keyword in enumerate(keywords):
            results = get_all_results(keyword, max_pages, api_key)

            if results:
                rankings = {"keyword": keyword}
                for site in all_sites:
                    rank = find_ranking(results, site)
                    rankings[site] = rank
                all_rankings.append(rankings)
                all_serp_data[keyword] = results

            overall_progress.progress((i + 1) / len(keywords))

        status_text.text("âœ… å®Œæˆï¼")

        # å„²å­˜çµæœ
        st.session_state.current_results = {
            "rankings": all_rankings,
            "serp_data": all_serp_data,
            "timestamp": datetime.now().isoformat()
        }

        # åŠ å…¥æ­·å²è¨˜éŒ„
        record = {
            "rankings": all_rankings,
            "my_sites": my_sites,
            "competitors": competitors,
            "region": search_region
        }
        st.session_state.history = add_record(st.session_state.history, record)

        st.success("âœ… æ•¸æ“šå·²å„²å­˜åˆ°æ­·å²è¨˜éŒ„")

    # ============ é¡¯ç¤ºçµæœ ============

    if st.session_state.current_results:
        st.markdown("---")
        st.markdown("## ğŸ“Š æ’åçµæœ")

        results = st.session_state.current_results
        rankings = results["rankings"]
        all_sites = my_sites + competitors

        # ç²å–ä¸Šæ¬¡è¨˜éŒ„ç”¨æ–¼æ¯”è¼ƒ
        history_records = st.session_state.history.get("records", [])
        previous_rankings = {}
        if len(history_records) >= 2:
            prev_record = history_records[-2]
            for item in prev_record.get("rankings", []):
                kw = item.get("keyword")
                previous_rankings[kw] = item

        # çµ±è¨ˆå¡ç‰‡
        st.markdown("### ğŸ“ˆ ç¸½è¦½")

        col1, col2, col3, col4 = st.columns(4)

        # è¨ˆç®—çµ±è¨ˆ
        top3_count = 0
        top10_count = 0
        improved_count = 0
        declined_count = 0

        for rank_data in rankings:
            for site in my_sites:
                rank = rank_data.get(site)
                if rank is not None:
                    if rank <= 3:
                        top3_count += 1
                    if rank <= 10:
                        top10_count += 1

                    # æ¯”è¼ƒè®ŠåŒ–
                    kw = rank_data.get("keyword")
                    if kw in previous_rankings:
                        prev_rank = previous_rankings[kw].get(site)
                        if prev_rank is not None:
                            if rank < prev_rank:
                                improved_count += 1
                            elif rank > prev_rank:
                                declined_count += 1

        with col1:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{top3_count}</div>
                <div class="stat-label">ğŸ† å‰ 3 å</div>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number">{top10_count}</div>
                <div class="stat-label">ğŸ“„ é¦–é æ’å</div>
            </div>
            """, unsafe_allow_html=True)

        with col3:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number" style="color: #10B981;">{improved_count}</div>
                <div class="stat-label">ğŸ“ˆ æ’åä¸Šå‡</div>
            </div>
            """, unsafe_allow_html=True)

        with col4:
            st.markdown(f"""
            <div class="stat-card">
                <div class="stat-number" style="color: #EF4444;">{declined_count}</div>
                <div class="stat-label">ğŸ“‰ æ’åä¸‹é™</div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("---")

        # è©³ç´°æ’åè¡¨æ ¼
        st.markdown("### ğŸ“‹ è©³ç´°æ’å")

        # å»ºç«‹é¡¯ç¤ºç”¨çš„ DataFrame
        display_data = []
        for rank_data in rankings:
            row = {"é—œéµå­—": rank_data.get("keyword")}

            for site in all_sites:
                rank = rank_data.get(site)
                kw = rank_data.get("keyword")

                # è¨ˆç®—è®ŠåŒ–
                change = ""
                if kw in previous_rankings:
                    prev_rank = previous_rankings[kw].get(site)
                    if prev_rank is not None and rank is not None:
                        diff = prev_rank - rank  # æ­£æ•¸è¡¨ç¤ºä¸Šå‡
                        if diff > 0:
                            change = f" â†‘{diff}"
                        elif diff < 0:
                            change = f" â†“{abs(diff)}"
                        else:
                            change = " â”€"

                if rank is not None:
                    row[site] = f"{rank}{change}"
                else:
                    row[site] = "N/A"

            display_data.append(row)

        df_display = pd.DataFrame(display_data)


        # é¡¯ç¤ºè¡¨æ ¼
        def highlight_ranking(val):
            if "N/A" in str(val):
                return "background-color: #FEE2E2; color: #DC2626;"
            try:
                rank = int(str(val).split()[0].replace("â†‘", "").replace("â†“", "").replace("â”€", ""))
                if rank <= 3:
                    return "background-color: #D1FAE5; color: #065F46; font-weight: bold;"
                elif rank <= 10:
                    return "background-color: #FEF3C7; color: #92400E;"
                elif rank <= 20:
                    return "background-color: #F3F4F6; color: #374151;"
            except:
                pass
            return ""


        st.dataframe(
            df_display.style.applymap(highlight_ranking, subset=all_sites),
            use_container_width=True,
            height=400
        )

        # åœ–ä¾‹èªªæ˜
        st.markdown("""
        **åœ–ä¾‹ï¼š** 
        ğŸŸ¢ å‰ 3 å | ğŸŸ¡ é¦–é  (4-10) | âšª ç¬¬äºŒé  (11-20) | ğŸ”´ æœªä¸Šæ¦œ
        | â†‘ ä¸Šå‡ | â†“ ä¸‹é™ | â”€ æŒå¹³
        """)

        # ä¸‹è¼‰æŒ‰éˆ•
        st.markdown("---")


        def create_excel(rankings, serp_data, my_sites, competitors):
            output = BytesIO()
            with pd.ExcelWriter(output, engine="openpyxl") as writer:
                # æ’åç¸½è¦½
                df_rankings = pd.DataFrame(rankings)
                df_rankings.to_excel(writer, sheet_name="æ’åç¸½è¦½", index=False)

                # å®Œæ•´ SERP
                serp_records = []
                for keyword, results in serp_data.items():
                    for result in results:
                        serp_records.append({
                            "é—œéµå­—": keyword,
                            "æ’å": result.get("actual_rank"),
                            "æ¨™é¡Œ": result.get("title"),
                            "ç¶²å€": result.get("link"),
                            "æè¿°": result.get("snippet", "")[:200]
                        })
                df_serp = pd.DataFrame(serp_records)
                df_serp.to_excel(writer, sheet_name="å®Œæ•´SERP", index=False)

            output.seek(0)
            return output


        col_dl1, col_dl2 = st.columns(2)

        with col_dl1:
            excel_file = create_excel(
                rankings,
                results.get("serp_data", {}),
                my_sites,
                competitors
            )
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
                data=excel_file,
                file_name=f"serp_ranking_{timestamp}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )

        with col_dl2:
            csv_data = df_display.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ CSV",
                data=csv_data,
                file_name=f"serp_ranking_{timestamp}.csv",
                mime="text/csv",
                use_container_width=True
            )

# ============ Tab 2: æ­·å²è¶¨å‹¢ ============

with tab2:
    st.markdown("### ğŸ“ˆ æ’åè¶¨å‹¢åœ–")

    history_records = st.session_state.history.get("records", [])

    if len(history_records) < 2:
        st.info("ğŸ“Š éœ€è¦è‡³å°‘ 2 æ¬¡è¨˜éŒ„æ‰èƒ½é¡¯ç¤ºè¶¨å‹¢åœ–ã€‚è«‹å…ˆåŸ·è¡Œæ’åæŸ¥è©¢ã€‚")
    else:
        # æ”¶é›†æ‰€æœ‰é—œéµå­—
        all_keywords = set()
        all_tracked_sites = set()
        for record in history_records:
            for item in record.get("rankings", []):
                all_keywords.add(item.get("keyword"))
            all_tracked_sites.update(record.get("my_sites", []))
            all_tracked_sites.update(record.get("competitors", []))

        # é¸æ“‡è¦æŸ¥çœ‹çš„é—œéµå­—å’Œç¶²ç«™
        col1, col2 = st.columns(2)
        with col1:
            selected_keyword = st.selectbox("é¸æ“‡é—œéµå­—", sorted(list(all_keywords)))
        with col2:
            selected_site = st.selectbox("é¸æ“‡ç¶²ç«™", sorted(list(all_tracked_sites)))

        # å»ºç«‹è¶¨å‹¢æ•¸æ“š
        trend_data = []
        for record in history_records:
            date = record.get("date", "æœªçŸ¥")
            for item in record.get("rankings", []):
                if item.get("keyword") == selected_keyword:
                    rank = item.get(selected_site)
                    trend_data.append({
                        "æ—¥æœŸ": date,
                        "æ’å": rank if rank is not None else None
                    })
                    break

        if trend_data:
            df_trend = pd.DataFrame(trend_data)
            df_trend = df_trend.dropna()

            if not df_trend.empty:
                # ä½¿ç”¨ Streamlit å…§å»ºåœ–è¡¨
                st.markdown(f"**ã€Œ{selected_keyword}ã€åœ¨ {selected_site} çš„æ’åè®ŠåŒ–**")

                # åè½‰æ’åé¡¯ç¤ºï¼ˆæ’åè¶Šä½è¶Šå¥½ï¼‰
                df_trend["æ’åï¼ˆè¶Šä½è¶Šå¥½ï¼‰"] = df_trend["æ’å"]
                st.line_chart(df_trend.set_index("æ—¥æœŸ")["æ’åï¼ˆè¶Šä½è¶Šå¥½ï¼‰"])

                # é¡¯ç¤ºæ•¸æ“šè¡¨
                st.markdown("#### ğŸ“‹ æ­·å²æ•¸æ“š")
                st.dataframe(df_trend, use_container_width=True)

                # è¨ˆç®—çµ±è¨ˆ
                st.markdown("#### ğŸ“Š çµ±è¨ˆæ‘˜è¦")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æœ€ä½³æ’å", int(df_trend["æ’å"].min()))
                with col2:
                    st.metric("æœ€å·®æ’å", int(df_trend["æ’å"].max()))
                with col3:
                    st.metric("å¹³å‡æ’å", f"{df_trend['æ’å'].mean():.1f}")
                with col4:
                    if len(df_trend) >= 2:
                        change = df_trend["æ’å"].iloc[0] - df_trend["æ’å"].iloc[-1]
                        st.metric("ç¸½è®ŠåŒ–", f"{change:+.0f}", delta=f"{change:+.0f}")
            else:
                st.warning("æ­¤é—œéµå­—/ç¶²ç«™çµ„åˆæ²’æœ‰æ’åæ•¸æ“š")
        else:
            st.warning("æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ•¸æ“š")

# ============ Tab 3: æ•¸æ“šåˆ†æ ============

with tab3:
    st.markdown("### ğŸ“Š SEO æ•¸æ“šåˆ†æ")

    history_records = st.session_state.history.get("records", [])

    if not history_records:
        st.info("ğŸ“Š é‚„æ²’æœ‰æ•¸æ“šã€‚è«‹å…ˆåŸ·è¡Œæ’åæŸ¥è©¢ã€‚")
    else:
        latest_record = history_records[-1]
        rankings = latest_record.get("rankings", [])
        tracked_my_sites = latest_record.get("my_sites", [])
        tracked_competitors = latest_record.get("competitors", [])

        if rankings:
            st.markdown("#### ğŸ† æ’ååˆ†ä½ˆï¼ˆæˆ‘çš„ç¶²ç«™ï¼‰")

            # è¨ˆç®—å„æ’åå€é–“æ•¸é‡
            rank_distribution = {"å‰3å": 0, "é¦–é (4-10)": 0, "ç¬¬2é (11-20)": 0, "20åå¤–": 0, "æœªä¸Šæ¦œ": 0}

            for item in rankings:
                for site in tracked_my_sites:
                    rank = item.get(site)
                    if rank is None:
                        rank_distribution["æœªä¸Šæ¦œ"] += 1
                    elif rank <= 3:
                        rank_distribution["å‰3å"] += 1
                    elif rank <= 10:
                        rank_distribution["é¦–é (4-10)"] += 1
                    elif rank <= 20:
                        rank_distribution["ç¬¬2é (11-20)"] += 1
                    else:
                        rank_distribution["20åå¤–"] += 1

            df_dist = pd.DataFrame([rank_distribution])
            st.bar_chart(df_dist.T)

            # ç«¶çˆ­å°æ‰‹æ¯”è¼ƒ
            st.markdown("#### âš”ï¸ èˆ‡ç«¶çˆ­å°æ‰‹æ¯”è¼ƒ")

            comparison_data = []
            all_sites = tracked_my_sites + tracked_competitors

            for site in all_sites:
                site_stats = {"ç¶²ç«™": site, "å¹³å‡æ’å": 0, "é¦–é æ•¸": 0, "ç¸½é—œéµå­—": 0}
                ranks = []
                for item in rankings:
                    rank = item.get(site)
                    if rank is not None:
                        ranks.append(rank)
                        if rank <= 10:
                            site_stats["é¦–é æ•¸"] += 1

                if ranks:
                    site_stats["å¹³å‡æ’å"] = round(sum(ranks) / len(ranks), 1)
                    site_stats["ç¸½é—œéµå­—"] = len(ranks)

                site_stats["é¡å‹"] = "æˆ‘çš„ç¶²ç«™" if site in tracked_my_sites else "ç«¶çˆ­å°æ‰‹"
                comparison_data.append(site_stats)

            df_comparison = pd.DataFrame(comparison_data)
            st.dataframe(df_comparison, use_container_width=True)

            # SEO å»ºè­°
            st.markdown("#### ğŸ’¡ SEO å»ºè­°")

            suggestions = []
            for item in rankings:
                kw = item.get("keyword")
                for site in tracked_my_sites:
                    rank = item.get(site)
                    if rank is None:
                        suggestions.append(f"âŒ **{kw}**ï¼šæœªä¸Šæ¦œï¼Œå»ºè­°å»ºç«‹ç›¸é—œå…§å®¹é é¢")
                    elif rank > 10 and rank <= 20:
                        suggestions.append(f"ğŸ”¶ **{kw}**ï¼šæ’å {rank}ï¼Œè·é›¢é¦–é åªå·®ä¸€é»ï¼Œå»ºè­°å„ªåŒ–å…§å®¹å’Œå»ºç«‹åå‘é€£çµ")
                    elif rank > 20:
                        suggestions.append(f"âš ï¸ **{kw}**ï¼šæ’å {rank}ï¼Œéœ€è¦è¼ƒå¤§å¹…åº¦çš„ SEO å„ªåŒ–")

            if suggestions:
                for s in suggestions[:10]:  # åªé¡¯ç¤ºå‰ 10 å€‹
                    st.markdown(s)
                if len(suggestions) > 10:
                    st.markdown(f"... é‚„æœ‰ {len(suggestions) - 10} å€‹å»ºè­°")
            else:
                st.success("ğŸ‰ è¡¨ç¾å¾ˆå¥½ï¼å¤§éƒ¨åˆ†é—œéµå­—éƒ½åœ¨é¦–é ")

# ============ Tab 4: ç®¡ç† ============

with tab4:
    st.markdown("### âš™ï¸ æ•¸æ“šç®¡ç†")

    history_records = st.session_state.history.get("records", [])

    st.markdown(f"**ç¸½è¨˜éŒ„æ•¸ï¼š** {len(history_records)}")

    if history_records:
        # é¡¯ç¤ºæ­·å²è¨˜éŒ„åˆ—è¡¨
        st.markdown("#### ğŸ“œ æ­·å²è¨˜éŒ„")

        for i, record in enumerate(reversed(history_records)):
            date = record.get("date", "æœªçŸ¥")
            timestamp = record.get("timestamp", "")
            keyword_count = len(record.get("rankings", []))

            with st.expander(f"ğŸ“… {date} ({keyword_count} å€‹é—œéµå­—)"):
                st.json(record.get("rankings", []))

        st.markdown("---")

        # åŒ¯å‡ºæ‰€æœ‰æ•¸æ“š
        st.markdown("#### ğŸ’¾ åŒ¯å‡ºæ•¸æ“š")

        col1, col2 = st.columns(2)

        with col1:
            json_data = json.dumps(st.session_state.history, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ åŒ¯å‡º JSON å‚™ä»½",
                data=json_data,
                file_name=f"serp_history_backup_{datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json",
                use_container_width=True
            )

        with col2:
            # åŒ¯å‡ºç‚º Excel
            all_records = []
            for record in history_records:
                date = record.get("date", "")
                for item in record.get("rankings", []):
                    row = {"æ—¥æœŸ": date, **item}
                    all_records.append(row)

            if all_records:
                df_all = pd.DataFrame(all_records)
                output = BytesIO()
                df_all.to_excel(output, index=False, engine="openpyxl")
                output.seek(0)

                st.download_button(
                    label="ğŸ“¥ åŒ¯å‡ºæ‰€æœ‰æ­·å² Excel",
                    data=output,
                    file_name=f"serp_all_history_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )

        st.markdown("---")

        # æ¸…é™¤æ•¸æ“š
        st.markdown("#### ğŸ—‘ï¸ æ¸…é™¤æ•¸æ“š")
        st.warning("âš ï¸ æ­¤æ“ä½œç„¡æ³•å¾©åŸ")

        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ­·å²è¨˜éŒ„", type="secondary"):
            st.session_state.history = {"records": [], "settings": {}}
            save_history(st.session_state.history)
            st.success("âœ… å·²æ¸…é™¤æ‰€æœ‰è¨˜éŒ„")
            st.rerun()
    else:
        st.info("é‚„æ²’æœ‰æ­·å²è¨˜éŒ„")

    # åŒ¯å…¥æ•¸æ“š
    st.markdown("---")
    st.markdown("#### ğŸ“¤ åŒ¯å…¥æ•¸æ“š")

    uploaded_file = st.file_uploader("ä¸Šå‚³ JSON å‚™ä»½æª”æ¡ˆ", type=["json"])
    if uploaded_file:
        try:
            imported_data = json.load(uploaded_file)
            if st.button("ç¢ºèªåŒ¯å…¥"):
                st.session_state.history = imported_data
                save_history(imported_data)
                st.success("âœ… åŒ¯å…¥æˆåŠŸï¼")
                st.rerun()
        except Exception as e:
            st.error(f"åŒ¯å…¥å¤±æ•—ï¼š{e}")

# ============ é å°¾ ============

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem;">
    <p>ğŸš€ SEO æ’åè¿½è¹¤å·¥å…· Pro</p>
    <p style="font-size: 0.8rem;">Powered by Serper API | Made with Streamlit</p>
</div>
""", unsafe_allow_html=True)
