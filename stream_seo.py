import streamlit as st
import requests
import pandas as pd
import time
import json
import os
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from io import BytesIO
import random

# ============ é é¢è¨­å®š ============

st.set_page_config(
    page_title="SEO æ’åè¿½è¹¤å·¥å…· Pro",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============ è‡ªè¨‚ CSS ============

st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 2rem;
        text-align: center;
    }

    .project-header {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        padding: 1rem 1.5rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 1rem;
    }

    .debug-box {
        background: #1a1a2e;
        color: #00ff88;
        padding: 1rem;
        border-radius: 8px;
        font-family: monospace;
        font-size: 0.85rem;
        max-height: 300px;
        overflow-y: auto;
    }

    .stat-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        text-align: center;
        margin-bottom: 0.5rem;
        border-left: 4px solid #667eea;
    }

    .keyword-item {
        padding: 0.4rem 0;
        border-bottom: 1px solid #f0f0f0;
        font-size: 0.95rem;
    }

    .keyword-item:last-child {
        border-bottom: none;
    }

    .keyword-rank {
        display: inline-block;
        min-width: 45px;
        padding: 0.15rem 0.5rem;
        border-radius: 4px;
        font-weight: bold;
        font-size: 0.85rem;
        margin-right: 0.5rem;
    }

    .rank-top3 {
        background: #DBEAFE;
        color: #1E40AF;
    }

    .rank-top10 {
        background: #E0F2FE;
        color: #0369A1;
    }

    .rank-top20 {
        background: #FEF3C7;
        color: #92400E;
    }

    .rank-top30 {
        background: #F3E8FF;
        color: #7C3AED;
    }

    .rank-warning {
        background: #FEE2E2;
        color: #DC2626;
    }

    .rank-na {
        background: #F3F4F6;
        color: #6B7280;
    }

    .site-analysis-card {
        background: white;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 1.5rem;
        margin-bottom: 1rem;
    }

    /* æ¸›å°‘å´é‚Šæ¬„å…ƒç´ é–“è· */
    .sidebar-section {
        margin-bottom: 0.5rem !important;
    }

    [data-testid="stSidebar"] .stSelectbox,
    [data-testid="stSidebar"] .stRadio,
    [data-testid="stSidebar"] .stSlider {
        margin-bottom: 0.3rem !important;
    }

    [data-testid="stSidebar"] .stMarkdown p {
        margin-bottom: 0.3rem !important;
    }
</style>
""", unsafe_allow_html=True)

# ============ æ•¸æ“šå„²å­˜åŠŸèƒ½ ============

DATA_DIR = "seo_data"
PROJECTS_FILE = os.path.join(DATA_DIR, "projects.json")


def ensure_data_dir():
    """ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨"""
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)


def get_project_file(project_id):
    """ç²å–å°ˆæ¡ˆæ•¸æ“šæª”æ¡ˆè·¯å¾‘"""
    ensure_data_dir()
    return os.path.join(DATA_DIR, f"project_{project_id}.json")


def load_projects():
    """è¼‰å…¥æ‰€æœ‰å°ˆæ¡ˆåˆ—è¡¨"""
    ensure_data_dir()
    if os.path.exists(PROJECTS_FILE):
        try:
            with open(PROJECTS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {"projects": [], "active_project": None}
    return {"projects": [], "active_project": None}


def save_projects(data):
    """å„²å­˜å°ˆæ¡ˆåˆ—è¡¨"""
    ensure_data_dir()
    with open(PROJECTS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_project_data(project_id):
    """è¼‰å…¥ç‰¹å®šå°ˆæ¡ˆçš„æ•¸æ“š"""
    file_path = get_project_file(project_id)
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {"records": [], "keyword_groups": {}, "settings": {}}
    return {"records": [], "keyword_groups": {}, "settings": {}}


def save_project_data(project_id, data):
    """å„²å­˜ç‰¹å®šå°ˆæ¡ˆçš„æ•¸æ“š"""
    file_path = get_project_file(project_id)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def create_project(name, industry, description="", my_sites=None, competitors=None, icon="ğŸ“Š"):
    """å‰µå»ºæ–°å°ˆæ¡ˆ"""
    projects_data = load_projects()

    project_id = f"proj_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}"

    new_project = {
        "id": project_id,
        "name": name,
        "industry": industry,
        "description": description,
        "icon": icon,
        "my_sites": my_sites or [],
        "competitors": competitors or [],
        "created": datetime.now().isoformat(),
        "updated": datetime.now().isoformat(),
        "record_count": 0
    }

    projects_data["projects"].append(new_project)

    if len(projects_data["projects"]) == 1:
        projects_data["active_project"] = project_id

    save_projects(projects_data)
    save_project_data(project_id, {"records": [], "keyword_groups": {}, "settings": {}})

    return project_id


def delete_project(project_id):
    """åˆªé™¤å°ˆæ¡ˆ"""
    projects_data = load_projects()

    projects_data["projects"] = [p for p in projects_data["projects"] if p["id"] != project_id]

    if projects_data["active_project"] == project_id:
        if projects_data["projects"]:
            projects_data["active_project"] = projects_data["projects"][0]["id"]
        else:
            projects_data["active_project"] = None

    save_projects(projects_data)

    file_path = get_project_file(project_id)
    if os.path.exists(file_path):
        os.remove(file_path)


def update_project(project_id, updates):
    """æ›´æ–°å°ˆæ¡ˆè³‡è¨Š"""
    projects_data = load_projects()

    for project in projects_data["projects"]:
        if project["id"] == project_id:
            project.update(updates)
            project["updated"] = datetime.now().isoformat()
            break

    save_projects(projects_data)


def set_active_project(project_id):
    """è¨­å®šæ´»èºå°ˆæ¡ˆ"""
    projects_data = load_projects()
    projects_data["active_project"] = project_id
    save_projects(projects_data)


def get_active_project():
    """ç²å–ç•¶å‰æ´»èºå°ˆæ¡ˆ"""
    projects_data = load_projects()
    active_id = projects_data.get("active_project")

    if active_id:
        for project in projects_data["projects"]:
            if project["id"] == active_id:
                return project

    return None


def add_record_to_project(project_id, record):
    """æ·»åŠ è¨˜éŒ„åˆ°å°ˆæ¡ˆ"""
    record["timestamp"] = datetime.now().isoformat()
    record["date"] = datetime.now().strftime("%Y-%m-%d")
    record["time"] = datetime.now().strftime("%H:%M:%S")
    record["id"] = f"{record['date']}_{record['time'].replace(':', '')}"

    project_data = load_project_data(project_id)
    project_data["records"].append(record)
    save_project_data(project_id, project_data)

    projects_data = load_projects()
    for project in projects_data["projects"]:
        if project["id"] == project_id:
            project["record_count"] = len(project_data["records"])
            project["updated"] = datetime.now().isoformat()
            break
    save_projects(projects_data)

    return record


# ============ è¡Œæ¥­é è¨­é…ç½® ============

INDUSTRY_PRESETS = {
    "catering": {
        "name": "åˆ°æœƒ/é¤é£²",
        "icon": "ğŸ½ï¸",
        "keywords_example": "åˆ°æœƒ\nåˆ°æœƒæ¨ä»‹\næ´¾å°åˆ°æœƒ\nå…¬å¸åˆ°æœƒ\nç”Ÿæ—¥æœƒåˆ°æœƒ\nç™¾æ—¥å®´åˆ°æœƒ\næ»¿æœˆé…’åˆ°æœƒ\nå¤–è³£åˆ°æœƒ",
        "sites_example": "daynightcatering.com\ncateringbear.com",
        "competitors_example": "cateringmama.com\nkamadelivery.com"
    },
    "smoking": {
        "name": "ç…™å…·",
        "icon": "ğŸš¬",
        "keywords_example": "é›»å­ç…™\nvape\nç…™æ²¹\néœ§åŒ–å™¨\nä¸€æ¬¡æ€§é›»å­ç…™",
        "sites_example": "",
        "competitors_example": ""
    },
    "moving": {
        "name": "æ¬å±‹/æ¬é‹",
        "icon": "ğŸšš",
        "keywords_example": "æ¬å±‹\næ¬å±‹å…¬å¸\næ¬é‹æœå‹™\næ¬å±‹åƒ¹éŒ¢\nè¿·ä½ å€‰",
        "sites_example": "",
        "competitors_example": ""
    },
    "renovation": {
        "name": "è£ä¿®",
        "icon": "ğŸ”¨",
        "keywords_example": "è£ä¿®\nè£ä¿®å…¬å¸\nå®¤å…§è¨­è¨ˆ\nå®¶å±…è£ä¿®\nå»šæˆ¿è£ä¿®",
        "sites_example": "",
        "competitors_example": ""
    },
    "education": {
        "name": "æ•™è‚²/è£œç¿’",
        "icon": "ğŸ“š",
        "keywords_example": "è£œç¿’\nè£œç¿’ç¤¾\nç§äººè£œç¿’\nè‹±æ–‡è£œç¿’\næ•¸å­¸è£œç¿’",
        "sites_example": "",
        "competitors_example": ""
    },
    "beauty": {
        "name": "ç¾å®¹",
        "icon": "ğŸ’„",
        "keywords_example": "ç¾å®¹é™¢\nfacial\nè­·è†š\nè„«æ¯›\né†«ç¾",
        "sites_example": "",
        "competitors_example": ""
    },
    "medical": {
        "name": "é†«ç™‚/è¨ºæ‰€",
        "icon": "ğŸ¥",
        "keywords_example": "è¨ºæ‰€\nç‰™é†«\nä¸­é†«\nç‰©ç†æ²»ç™‚\nçš®è†šç§‘",
        "sites_example": "",
        "competitors_example": ""
    },
    "legal": {
        "name": "æ³•å¾‹",
        "icon": "âš–ï¸",
        "keywords_example": "å¾‹å¸«\né›¢å©šå¾‹å¸«\næ³•å¾‹è«®è©¢\nåˆ‘äº‹å¾‹å¸«\næ°‘äº‹è¨´è¨Ÿ",
        "sites_example": "",
        "competitors_example": ""
    },
    "realestate": {
        "name": "åœ°ç”¢",
        "icon": "ğŸ ",
        "keywords_example": "è²·æ¨“\nç§Ÿå±‹\nåœ°ç”¢ä»£ç†\næ¨“ç›¤\näºŒæ‰‹æ¨“",
        "sites_example": "",
        "competitors_example": ""
    },
    "other": {
        "name": "å…¶ä»–",
        "icon": "ğŸ“Š",
        "keywords_example": "",
        "sites_example": "",
        "competitors_example": ""
    }
}


# ============ å·¥å…·å‡½æ•¸ ============

def normalize_domain(domain):
    """æ¨™æº–åŒ–ç¶²åŸŸåç¨±"""
    domain = domain.lower().strip()
    domain = domain.replace("https://", "").replace("http://", "")
    domain = domain.rstrip("/")
    if domain.startswith("www."):
        domain = domain[4:]
    return domain


def get_record_display_name(record):
    """ç²å–è¨˜éŒ„çš„é¡¯ç¤ºåç¨±"""
    date = record.get("date", "æœªçŸ¥")
    time_str = record.get("time", "")
    keyword_count = len(record.get("rankings", []))
    return f"{date} {time_str} ({keyword_count}å€‹é—œéµå­—)"


def get_all_sites_from_record(record):
    """å¾è¨˜éŒ„ä¸­ç²å–æ‰€æœ‰ç¶²ç«™"""
    all_sites = []
    seen = set()

    for site in record.get("my_sites", []):
        normalized = normalize_domain(site)
        if normalized not in seen:
            seen.add(normalized)
            all_sites.append(site)

    for site in record.get("competitors", []):
        normalized = normalize_domain(site)
        if normalized not in seen:
            seen.add(normalized)
            all_sites.append(site)

    return all_sites


def get_keyword_order_map(record):
    """ç²å–é—œéµå­—çš„åŸå§‹é †åºæ˜ å°„"""
    keywords = record.get("keywords", [])
    return {kw: idx for idx, kw in enumerate(keywords)}


def analyze_keyword_competition(rankings, site_a, site_b, keyword_order_map=None):
    """åˆ†æå…©å€‹ç¶²ç«™ä¹‹é–“çš„é—œéµå­—ç«¶çˆ­"""
    winning = []
    losing = []
    both_ranked = []
    only_a = []
    only_b = []
    neither = []

    site_a_normalized = normalize_domain(site_a)
    site_b_normalized = normalize_domain(site_b)

    for item in rankings:
        keyword = item.get("keyword")

        rank_a = None
        for key in item.keys():
            if key != "keyword" and normalize_domain(key) == site_a_normalized:
                rank_a = item.get(key)
                break

        rank_b = None
        for key in item.keys():
            if key != "keyword" and normalize_domain(key) == site_b_normalized:
                rank_b = item.get(key)
                break

        order = keyword_order_map.get(keyword, 9999) if keyword_order_map else 0

        if rank_a is None and rank_b is None:
            neither.append({"keyword": keyword, "order": order})
        elif rank_a is None:
            only_b.append({"keyword": keyword, "rank_b": rank_b, "order": order})
        elif rank_b is None:
            only_a.append({"keyword": keyword, "rank_a": rank_a, "order": order})
        else:
            both_ranked.append({
                "keyword": keyword,
                "rank_a": rank_a,
                "rank_b": rank_b,
                "diff": rank_b - rank_a,
                "order": order
            })
            if rank_a < rank_b:
                winning.append({"keyword": keyword, "rank_a": rank_a, "rank_b": rank_b, "order": order})
            elif rank_a > rank_b:
                losing.append({"keyword": keyword, "rank_a": rank_a, "rank_b": rank_b, "order": order})

    winning.sort(key=lambda x: x["order"])
    losing.sort(key=lambda x: x["order"])
    only_a.sort(key=lambda x: x["order"])
    only_b.sort(key=lambda x: x["order"])
    neither.sort(key=lambda x: x["order"])
    both_ranked.sort(key=lambda x: x["order"])

    return {
        "winning": winning,
        "losing": losing,
        "both_ranked": both_ranked,
        "only_a": only_a,
        "only_b": only_b,
        "neither": neither
    }


def analyze_site_keywords_detail(rankings, site, warning_threshold=20, keyword_order_map=None):
    """åˆ†æå–®ä¸€ç¶²ç«™çš„é—œéµå­—è©³æƒ…ï¼ˆå¸¶æ’åï¼‰"""
    site_normalized = normalize_domain(site)

    details = {
        "top3": [],
        "top10": [],
        "top20": [],
        "top30": [],
        "warning": [],
        "na": []
    }

    for item in rankings:
        keyword = item.get("keyword")
        order = keyword_order_map.get(keyword, 9999) if keyword_order_map else 0

        rank = None
        for key in item.keys():
            if key != "keyword" and normalize_domain(key) == site_normalized:
                rank = item.get(key)
                break

        if rank is None:
            details["na"].append({"keyword": keyword, "order": order})
        else:
            if rank <= 3:
                details["top3"].append({"keyword": keyword, "rank": rank, "order": order})
            elif rank <= 10:
                details["top10"].append({"keyword": keyword, "rank": rank, "order": order})
            elif rank <= 20:
                details["top20"].append({"keyword": keyword, "rank": rank, "order": order})
            elif rank <= 30:
                details["top30"].append({"keyword": keyword, "rank": rank, "order": order})

            if rank > warning_threshold:
                details["warning"].append({"keyword": keyword, "rank": rank, "order": order})

    for key in details:
        details[key].sort(key=lambda x: x["order"])

    return details


def export_single_record(record):
    """åŒ¯å‡ºå–®ä¸€è¨˜éŒ„ç‚º Excel"""
    output = BytesIO()

    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_rankings = pd.DataFrame(record.get("rankings", []))
        df_rankings.to_excel(writer, sheet_name="æ’å", index=False)

        info_data = {
            "é …ç›®": ["æ—¥æœŸ", "æ™‚é–“", "åœ°å€", "æˆ‘çš„ç¶²ç«™", "ç«¶çˆ­å°æ‰‹"],
            "å…§å®¹": [
                record.get("date", ""),
                record.get("time", ""),
                record.get("region", ""),
                ", ".join(record.get("my_sites", [])),
                ", ".join(record.get("competitors", []))
            ]
        }
        pd.DataFrame(info_data).to_excel(writer, sheet_name="æŸ¥è©¢è³‡è¨Š", index=False)

    output.seek(0)
    return output


def create_styled_ranking_dataframe(rankings, my_sites, competitors, warning_threshold, previous_rankings=None):
    """å‰µå»ºå¸¶æ¨£å¼çš„æ’å DataFrame"""
    all_sites = my_sites + competitors

    display_data = []
    for rank_data in rankings:
        row = {"é—œéµå­—": rank_data.get("keyword")}

        for site in all_sites:
            site_normalized = normalize_domain(site)
            rank = None

            for key in rank_data.keys():
                if key != "keyword" and normalize_domain(key) == site_normalized:
                    rank = rank_data.get(key)
                    break

            kw = rank_data.get("keyword")

            change = ""
            if previous_rankings and kw in previous_rankings:
                prev_data = previous_rankings[kw]
                prev_rank = None
                for key in prev_data.keys():
                    if key != "keyword" and normalize_domain(key) == site_normalized:
                        prev_rank = prev_data.get(key)
                        break

                if prev_rank is not None and rank is not None:
                    diff = prev_rank - rank
                    if diff > 0:
                        change = f" â†‘{diff}"
                    elif diff < 0:
                        change = f" â†“{abs(diff)}"
                    else:
                        change = " â”€"

            row[site] = f"{rank}{change}" if rank is not None else "N/A"

        display_data.append(row)

    df_display = pd.DataFrame(display_data)

    def style_ranking_cell(val, col_name):
        is_my_site = col_name in my_sites

        if "N/A" in str(val):
            if is_my_site:
                return "background-color: #FEF2F2; color: #B91C1C;"
            else:
                return "background-color: #F9FAFB; color: #9CA3AF;"

        try:
            rank = int(str(val).split()[0])

            if is_my_site:
                if rank <= 3:
                    return "background-color: #DBEAFE; color: #1E40AF; font-weight: bold;"
                elif rank <= 10:
                    return "background-color: #E0F2FE; color: #0369A1;"
                elif rank <= 20:
                    return "background-color: #F0F9FF; color: #0C4A6E;"
                elif rank > warning_threshold:
                    return "background-color: #FEE2E2; color: #DC2626; font-weight: bold;"
                else:
                    return "background-color: #F8FAFC; color: #475569;"
            else:
                if rank <= 3:
                    return "background-color: #FEF3C7; color: #92400E; font-weight: bold;"
                elif rank <= 10:
                    return "background-color: #FFFBEB; color: #B45309;"
                elif rank <= 20:
                    return "background-color: #F9FAFB; color: #6B7280;"
                else:
                    return "background-color: #F3F4F6; color: #9CA3AF;"
        except:
            return ""

    def apply_styles(df):
        styles = pd.DataFrame('', index=df.index, columns=df.columns)
        for col in df.columns:
            if col != "é—œéµå­—":
                styles[col] = df[col].apply(lambda x: style_ranking_cell(x, col))
        return styles

    styled_df = df_display.style.apply(lambda _: apply_styles(df_display), axis=None)

    return df_display, styled_df


# ============ é¡¯ç¤ºé—œéµå­—åˆ—è¡¨çš„å‡½æ•¸ï¼ˆä¸€è¡Œä¸€å€‹ï¼‰============

def display_keyword_list(keywords_list, rank_class="rank-top10", show_rank=True):
    """é¡¯ç¤ºé—œéµå­—åˆ—è¡¨ï¼ˆä¸€è¡Œä¸€å€‹ï¼‰"""
    if not keywords_list:
        return

    for item in keywords_list:
        if isinstance(item, dict):
            keyword = item.get("keyword", "")
            rank = item.get("rank", "")

            if show_rank and rank:
                # æ ¹æ“šæ’åæ±ºå®šé¡è‰²
                if rank <= 3:
                    bg_color = "#DBEAFE"
                    text_color = "#1E40AF"
                elif rank <= 10:
                    bg_color = "#E0F2FE"
                    text_color = "#0369A1"
                elif rank <= 20:
                    bg_color = "#FEF3C7"
                    text_color = "#92400E"
                elif rank <= 30:
                    bg_color = "#F3E8FF"
                    text_color = "#7C3AED"
                else:
                    bg_color = "#FEE2E2"
                    text_color = "#DC2626"

                col1, col2 = st.columns([1, 8])
                with col1:
                    st.markdown(f"""
                    <span style="
                        display: inline-block;
                        min-width: 45px;
                        padding: 0.2rem 0.6rem;
                        border-radius: 4px;
                        font-weight: bold;
                        font-size: 0.85rem;
                        background: {bg_color};
                        color: {text_color};
                        text-align: center;
                    ">#{rank}</span>
                    """, unsafe_allow_html=True)
                with col2:
                    st.markdown(f"**{keyword}**")
            else:
                col1, col2 = st.columns([1, 8])
                with col1:
                    st.markdown("""
                    <span style="
                        display: inline-block;
                        min-width: 45px;
                        padding: 0.2rem 0.6rem;
                        border-radius: 4px;
                        font-weight: bold;
                        font-size: 0.85rem;
                        background: #F3F4F6;
                        color: #6B7280;
                        text-align: center;
                    ">N/A</span>
                    """, unsafe_allow_html=True)
                with col2:
                    st.markdown(f"{keyword}")
        else:
            # ç´”å­—ä¸²
            st.markdown(f"â€¢ {item}")

# ============ æœå°‹å¼•æ“é¡åˆ¥ ============

class StableSerpSearcher:
    """ç©©å®šç‰ˆ SERP æœå°‹å™¨"""

    def __init__(self, api_key, region="hk", lang="zh-tw", max_concurrent=10,
                 delay_between_requests=0.1, max_retries=3, autocorrect=False):
        self.api_key = api_key
        self.region = region
        self.lang = lang
        self.max_concurrent = max_concurrent
        self.delay = delay_between_requests
        self.max_retries = max_retries
        self.autocorrect = autocorrect
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

    def log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        log_entry = f"[{timestamp}] {message}"
        self.debug_logs.append(log_entry)

    async def _fetch_with_retry(self, session, keyword, page, semaphore):
        async with semaphore:
            await asyncio.sleep(random.uniform(0.05, self.delay))

            url = "https://google.serper.dev/search"
            payload = {
                "q": keyword,
                "gl": self.region,
                "hl": self.lang,
                "num": 10,
                "page": page,
                "autocorrect": self.autocorrect
            }
            headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json"
            }

            for attempt in range(self.max_retries):
                try:
                    async with session.post(url, json=payload, headers=headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            results = data.get("organic", [])

                            for result in results:
                                original_position = result.get("position", 0)
                                result["actual_rank"] = (page - 1) * 10 + original_position
                                result["page"] = page

                            self.success_count += 1
                            self.log(f"âœ… {keyword} (é {page}): å–å¾— {len(results)} å€‹çµæœ")

                            return {
                                "keyword": keyword,
                                "page": page,
                                "results": results,
                                "success": True
                            }

                        elif response.status == 429:
                            wait_time = (attempt + 1) * 2
                            self.log(f"âš ï¸ {keyword} (é {page}): é™æµï¼Œç­‰å¾… {wait_time}s")
                            await asyncio.sleep(wait_time)
                            continue

                        else:
                            self.log(f"âŒ {keyword} (é {page}): HTTP {response.status}")
                            if attempt < self.max_retries - 1:
                                await asyncio.sleep(1)
                                continue

                except asyncio.TimeoutError:
                    self.log(f"â±ï¸ {keyword} (é {page}): è¶…æ™‚")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(1)
                        continue

                except Exception as e:
                    self.log(f"âŒ {keyword} (é {page}): {str(e)[:50]}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(1)
                        continue

            self.fail_count += 1
            return {"keyword": keyword, "page": page, "results": [], "success": False}

    async def search_all_async(self, keywords, max_pages, progress_callback=None):
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

        tasks_info = [(kw, page) for kw in keywords for page in range(1, max_pages + 1)]
        total_tasks = len(tasks_info)

        self.log(f"ğŸš€ é–‹å§‹: {len(keywords)} é—œéµå­— Ã— {max_pages} é  = {total_tasks} è«‹æ±‚")
        self.log(f"ğŸ“ Autocorrect: {'é–‹å•Ÿ' if self.autocorrect else 'é—œé–‰'}")

        semaphore = asyncio.Semaphore(self.max_concurrent)
        connector = aiohttp.TCPConnector(limit=self.max_concurrent, ttl_dns_cache=300)
        timeout = aiohttp.ClientTimeout(total=30, connect=10)

        all_results = {kw: [] for kw in keywords}
        completed = 0

        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            coroutines = [
                self._fetch_with_retry(session, kw, page, semaphore)
                for kw, page in tasks_info
            ]

            for coro in asyncio.as_completed(coroutines):
                result = await coro
                completed += 1

                keyword = result["keyword"]
                if result["success"] and result["results"]:
                    all_results[keyword].extend(result["results"])

                if progress_callback:
                    progress_callback(completed, total_tasks, keyword)

        for keyword in all_results:
            all_results[keyword].sort(key=lambda x: x.get("actual_rank", 999))

        self.log(f"ğŸ“Š å®Œæˆ: æˆåŠŸ={self.success_count}, å¤±æ•—={self.fail_count}")
        return all_results

    def search_all(self, keywords, max_pages, progress_callback=None):
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(
                self.search_all_async(keywords, max_pages, progress_callback)
            )
        finally:
            loop.close()


class SequentialSerpSearcher:
    """é †åºæœå°‹å™¨"""

    def __init__(self, api_key, region="hk", lang="zh-tw", delay=0.3, autocorrect=False):
        self.api_key = api_key
        self.region = region
        self.lang = lang
        self.delay = delay
        self.autocorrect = autocorrect
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(pool_connections=5, pool_maxsize=5, max_retries=3)
        self.session.mount('https://', adapter)

    def log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        self.debug_logs.append(f"[{timestamp}] {message}")

    def _fetch_single(self, keyword, page):
        url = "https://google.serper.dev/search"
        payload = {
            "q": keyword,
            "gl": self.region,
            "hl": self.lang,
            "num": 10,
            "page": page,
            "autocorrect": self.autocorrect
        }
        headers = {"X-API-KEY": self.api_key, "Content-Type": "application/json"}

        try:
            response = self.session.post(url, json=payload, headers=headers, timeout=15)

            if response.status_code == 200:
                data = response.json()
                results = data.get("organic", [])

                for result in results:
                    result["actual_rank"] = (page - 1) * 10 + result.get("position", 0)
                    result["page"] = page

                self.success_count += 1
                self.log(f"âœ… {keyword} (é {page}): {len(results)} çµæœ")
                return results

            elif response.status_code == 429:
                self.log(f"âš ï¸ {keyword} (é {page}): é™æµ")
                time.sleep(2)
                return self._fetch_single(keyword, page)
            else:
                self.log(f"âŒ {keyword} (é {page}): HTTP {response.status_code}")
                self.fail_count += 1

        except Exception as e:
            self.log(f"âŒ {keyword} (é {page}): {str(e)[:30]}")
            self.fail_count += 1

        return []

    def search_all(self, keywords, max_pages, progress_callback=None):
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

        total = len(keywords) * max_pages
        completed = 0
        all_results = {}

        for keyword in keywords:
            all_results[keyword] = []
            for page in range(1, max_pages + 1):
                results = self._fetch_single(keyword, page)
                all_results[keyword].extend(results)
                completed += 1
                if progress_callback:
                    progress_callback(completed, total, keyword)
                time.sleep(self.delay)
            all_results[keyword].sort(key=lambda x: x.get("actual_rank", 999))

        return all_results


class BatchSerpSearcher:
    """æ‰¹æ¬¡æœå°‹å™¨"""

    def __init__(self, api_key, region="hk", lang="zh-tw",
                 batch_size=5, delay_between_batches=1.0, max_workers=5, autocorrect=False):
        self.api_key = api_key
        self.region = region
        self.lang = lang
        self.batch_size = batch_size
        self.batch_delay = delay_between_batches
        self.max_workers = max_workers
        self.autocorrect = autocorrect
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(pool_connections=max_workers, pool_maxsize=max_workers, max_retries=3)
        self.session.mount('https://', adapter)

    def log(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        self.debug_logs.append(f"[{timestamp}] {message}")

    def _fetch_single(self, keyword, page):
        url = "https://google.serper.dev/search"
        payload = {
            "q": keyword,
            "gl": self.region,
            "hl": self.lang,
            "num": 10,
            "page": page,
            "autocorrect": self.autocorrect
        }
        headers = {"X-API-KEY": self.api_key, "Content-Type": "application/json"}

        for attempt in range(3):
            try:
                response = self.session.post(url, json=payload, headers=headers, timeout=15)
                if response.status_code == 200:
                    data = response.json()
                    results = data.get("organic", [])
                    for result in results:
                        result["actual_rank"] = (page - 1) * 10 + result.get("position", 0)
                        result["page"] = page
                    self.success_count += 1
                    return {"keyword": keyword, "page": page, "results": results, "success": True}
                elif response.status_code == 429:
                    time.sleep((attempt + 1) * 2)
                    continue
            except Exception:
                if attempt < 2:
                    time.sleep(1)
                    continue

        self.fail_count += 1
        return {"keyword": keyword, "page": page, "results": [], "success": False}

    def search_all(self, keywords, max_pages, progress_callback=None):
        self.debug_logs = []
        self.success_count = 0
        self.fail_count = 0

        all_tasks = [(kw, page) for kw in keywords for page in range(1, max_pages + 1)]
        total_tasks = len(all_tasks)
        batches = [all_tasks[i:i + self.batch_size] for i in range(0, len(all_tasks), self.batch_size)]

        all_results = {kw: [] for kw in keywords}
        completed = 0

        for batch_idx, batch in enumerate(batches):
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = {executor.submit(self._fetch_single, kw, page): (kw, page) for kw, page in batch}
                for future in as_completed(futures):
                    result = future.result()
                    completed += 1
                    if result["success"]:
                        all_results[result["keyword"]].extend(result["results"])
                    if progress_callback:
                        progress_callback(completed, total_tasks, result["keyword"])

            if batch_idx < len(batches) - 1:
                time.sleep(self.batch_delay)

        for keyword in all_results:
            all_results[keyword].sort(key=lambda x: x.get("actual_rank", 999))

        return all_results


# ============ æ’ååˆ†æå·¥å…· ============

def find_rankings(serp_results, sites):
    """å¾ SERP çµæœä¸­æ‰¾å‡ºæŒ‡å®šç¶²ç«™çš„æ’å"""
    rankings = []

    for keyword, results in serp_results.items():
        row = {"keyword": keyword}

        for site in sites:
            rank = None
            site_normalized = normalize_domain(site)
            for result in results:
                link = result.get("link", "")
                link_normalized = normalize_domain(link)
                if site_normalized in link_normalized:
                    rank = result.get("actual_rank")
                    break
            row[site] = rank

        rankings.append(row)

    return rankings


# ============ åˆå§‹åŒ– Session State ============

if "projects_data" not in st.session_state:
    st.session_state.projects_data = load_projects()

if "current_results" not in st.session_state:
    st.session_state.current_results = None

if "debug_logs" not in st.session_state:
    st.session_state.debug_logs = []

if "current_tab" not in st.session_state:
    st.session_state.current_tab = 0

if "show_project_manager" not in st.session_state:
    st.session_state.show_project_manager = False

# ============ ç²å–ç•¶å‰å°ˆæ¡ˆ ============

active_project = get_active_project()
projects_data = st.session_state.projects_data

# ============ æ¨™é¡Œ ============

st.markdown("""
<div class="main-header">
    <h1>ğŸš€ SEO æ’åè¿½è¹¤å·¥å…· Pro</h1>
    <p>å¤šå°ˆæ¡ˆç®¡ç† Â· æ™ºèƒ½åˆ†æ Â· ç«¶çˆ­å°æ‰‹è¿½è¹¤</p>
</div>
""", unsafe_allow_html=True)

# ============ å°ˆæ¡ˆé¸æ“‡å™¨ï¼ˆé ‚éƒ¨ï¼‰ ============

projects_data = load_projects()

if projects_data["projects"]:
    col_project, col_btn = st.columns([4, 1])

    with col_project:
        project_options = [(p["id"], f"{p['icon']} {p['name']} ({p['industry']})") for p in projects_data["projects"]]
        current_project_id = active_project["id"] if active_project else None

        selected_idx = 0
        for i, (pid, _) in enumerate(project_options):
            if pid == current_project_id:
                selected_idx = i
                break

        selected_project = st.selectbox(
            "ğŸ¯ ç•¶å‰å°ˆæ¡ˆ",
            options=[p[1] for p in project_options],
            index=selected_idx,
            key="project_selector",
            label_visibility="collapsed"
        )

        for pid, pname in project_options:
            if pname == selected_project:
                if pid != current_project_id:
                    set_active_project(pid)
                    st.session_state.projects_data = load_projects()
                    st.session_state.current_results = None
                    st.rerun()
                break

    with col_btn:
        if st.button("âš™ï¸ ç®¡ç†å°ˆæ¡ˆ", use_container_width=True):
            st.session_state.show_project_manager = not st.session_state.show_project_manager
            st.rerun()

    active_project = get_active_project()

    if active_project:
        project_data = load_project_data(active_project["id"])
        record_count = len(project_data.get("records", []))

        st.markdown(f"""
        <div class="project-header">
            <span style="font-size: 1.5rem;">{active_project['icon']}</span>
            <span style="font-size: 1.2rem; font-weight: bold; margin-left: 0.5rem;">{active_project['name']}</span>
            <span style="opacity: 0.8; margin-left: 1rem;">| {active_project['industry']} | {record_count} æ¢è¨˜éŒ„</span>
        </div>
        """, unsafe_allow_html=True)

else:
    st.info("ğŸ‘‹ æ­¡è¿ä½¿ç”¨ï¼è«‹å…ˆå‰µå»ºä¸€å€‹å°ˆæ¡ˆä¾†é–‹å§‹è¿½è¹¤ SEO æ’åã€‚")
    st.session_state.show_project_manager = True

# ============ å°ˆæ¡ˆç®¡ç†é¢æ¿ ============

if st.session_state.show_project_manager:
    st.markdown("---")
    st.markdown("## ğŸ“ å°ˆæ¡ˆç®¡ç†")

    tab_create, tab_list, tab_import = st.tabs(["â• å‰µå»ºå°ˆæ¡ˆ", "ğŸ“‹ å°ˆæ¡ˆåˆ—è¡¨", "ğŸ“¤ åŒ¯å…¥/åŒ¯å‡º"])

    with tab_create:
        st.markdown("### å‰µå»ºæ–°å°ˆæ¡ˆ")

        col1, col2 = st.columns(2)

        with col1:
            new_project_name = st.text_input("å°ˆæ¡ˆåç¨± *", placeholder="ä¾‹å¦‚ï¼šåˆ°æœƒæ¥­å‹™ SEO")

            industry_options = list(INDUSTRY_PRESETS.keys())
            industry_labels = [f"{INDUSTRY_PRESETS[k]['icon']} {INDUSTRY_PRESETS[k]['name']}" for k in industry_options]

            selected_industry_label = st.selectbox("è¡Œæ¥­é¡å‹ *", industry_labels)
            selected_industry = industry_options[industry_labels.index(selected_industry_label)]

            preset = INDUSTRY_PRESETS[selected_industry]

            new_project_desc = st.text_area("å°ˆæ¡ˆæè¿°ï¼ˆé¸å¡«ï¼‰", placeholder="æè¿°é€™å€‹å°ˆæ¡ˆçš„ç›®æ¨™æˆ–å‚™è¨»")

        with col2:
            st.markdown("**æˆ‘çš„ç¶²ç«™**")
            new_my_sites = st.text_area(
                "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
                value=preset["sites_example"],
                height=100,
                key="new_proj_sites"
            )

            st.markdown("**ç«¶çˆ­å°æ‰‹**")
            new_competitors = st.text_area(
                "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
                value=preset["competitors_example"],
                height=100,
                key="new_proj_competitors"
            )

        if st.button("âœ… å‰µå»ºå°ˆæ¡ˆ", type="primary", use_container_width=True):
            if not new_project_name:
                st.error("âŒ è«‹è¼¸å…¥å°ˆæ¡ˆåç¨±")
            else:
                my_sites_list = [s.strip() for s in new_my_sites.split("\n") if s.strip()]
                competitors_list = [s.strip() for s in new_competitors.split("\n") if s.strip()]

                project_id = create_project(
                    name=new_project_name,
                    industry=preset["name"],
                    description=new_project_desc,
                    my_sites=my_sites_list,
                    competitors=competitors_list,
                    icon=preset["icon"]
                )

                st.session_state.projects_data = load_projects()
                set_active_project(project_id)
                st.success(f"âœ… å°ˆæ¡ˆã€Œ{new_project_name}ã€å‰µå»ºæˆåŠŸï¼")
                st.session_state.show_project_manager = False
                st.rerun()

    with tab_list:
        st.markdown("### æ‰€æœ‰å°ˆæ¡ˆ")

        projects = load_projects()["projects"]

        if not projects:
            st.info("é‚„æ²’æœ‰ä»»ä½•å°ˆæ¡ˆ")
        else:
            for project in projects:
                proj_data = load_project_data(project["id"])
                record_count = len(proj_data.get("records", []))
                keyword_group_count = len(proj_data.get("keyword_groups", {}))
                is_active = project["id"] == (active_project["id"] if active_project else None)

                with st.container():
                    col1, col2, col3, col4 = st.columns([3, 1, 1, 1])

                    with col1:
                        status = "ğŸŸ¢ " if is_active else ""
                        st.markdown(f"""
                        **{status}{project['icon']} {project['name']}**  
                        {project['industry']} | {record_count} è¨˜éŒ„ | {keyword_group_count} é—œéµå­—çµ„
                        """)
                        if project.get("description"):
                            st.caption(project["description"])

                    with col2:
                        if not is_active:
                            if st.button("åˆ‡æ›", key=f"switch_{project['id']}", use_container_width=True):
                                set_active_project(project["id"])
                                st.session_state.projects_data = load_projects()
                                st.session_state.current_results = None
                                st.rerun()
                        else:
                            st.markdown("**ä½¿ç”¨ä¸­**")

                    with col3:
                        if st.button("âœï¸ ç·¨è¼¯", key=f"edit_{project['id']}", use_container_width=True):
                            st.session_state[f"editing_project_{project['id']}"] = True
                            st.rerun()

                    with col4:
                        if st.button("ğŸ—‘ï¸", key=f"delete_{project['id']}", use_container_width=True):
                            st.session_state[f"confirm_delete_{project['id']}"] = True
                            st.rerun()

                    if st.session_state.get(f"confirm_delete_{project['id']}", False):
                        st.warning(f"âš ï¸ ç¢ºå®šè¦åˆªé™¤å°ˆæ¡ˆã€Œ{project['name']}ã€å—ï¼Ÿæ‰€æœ‰æ•¸æ“šå°‡è¢«æ°¸ä¹…åˆªé™¤ï¼")
                        col_yes, col_no = st.columns(2)
                        with col_yes:
                            if st.button("ç¢ºèªåˆªé™¤", key=f"confirm_yes_{project['id']}", type="primary"):
                                delete_project(project["id"])
                                st.session_state.projects_data = load_projects()
                                del st.session_state[f"confirm_delete_{project['id']}"]
                                st.success("å·²åˆªé™¤")
                                st.rerun()
                        with col_no:
                            if st.button("å–æ¶ˆ", key=f"confirm_no_{project['id']}"):
                                del st.session_state[f"confirm_delete_{project['id']}"]
                                st.rerun()

                    if st.session_state.get(f"editing_project_{project['id']}", False):
                        st.markdown("---")
                        col_e1, col_e2 = st.columns(2)

                        with col_e1:
                            edit_name = st.text_input("å°ˆæ¡ˆåç¨±", value=project["name"],
                                                      key=f"edit_name_{project['id']}")
                            edit_desc = st.text_area("æè¿°", value=project.get("description", ""),
                                                     key=f"edit_desc_{project['id']}")

                        with col_e2:
                            edit_sites = st.text_area(
                                "æˆ‘çš„ç¶²ç«™",
                                value="\n".join(project.get("my_sites", [])),
                                key=f"edit_sites_{project['id']}"
                            )
                            edit_competitors = st.text_area(
                                "ç«¶çˆ­å°æ‰‹",
                                value="\n".join(project.get("competitors", [])),
                                key=f"edit_comp_{project['id']}"
                            )

                        col_save, col_cancel = st.columns(2)
                        with col_save:
                            if st.button("ğŸ’¾ å„²å­˜", key=f"save_edit_{project['id']}", type="primary",
                                         use_container_width=True):
                                update_project(project["id"], {
                                    "name": edit_name,
                                    "description": edit_desc,
                                    "my_sites": [s.strip() for s in edit_sites.split("\n") if s.strip()],
                                    "competitors": [s.strip() for s in edit_competitors.split("\n") if s.strip()]
                                })
                                st.session_state.projects_data = load_projects()
                                del st.session_state[f"editing_project_{project['id']}"]
                                st.success("âœ… å·²æ›´æ–°")
                                st.rerun()
                        with col_cancel:
                            if st.button("å–æ¶ˆ", key=f"cancel_edit_{project['id']}", use_container_width=True):
                                del st.session_state[f"editing_project_{project['id']}"]
                                st.rerun()

                    st.markdown("---")

    with tab_import:
        st.markdown("### åŒ¯å…¥/åŒ¯å‡ºå°ˆæ¡ˆ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ“¥ åŒ¯å‡º")

            if projects_data["projects"]:
                export_data = {
                    "projects": projects_data["projects"],
                    "project_data": {}
                }
                for project in projects_data["projects"]:
                    export_data["project_data"][project["id"]] = load_project_data(project["id"])

                json_export = json.dumps(export_data, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ åŒ¯å‡ºæ‰€æœ‰å°ˆæ¡ˆ",
                    data=json_export,
                    file_name=f"seo_projects_backup_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json",
                    use_container_width=True
                )

                if active_project:
                    single_export = {
                        "project": active_project,
                        "data": load_project_data(active_project["id"])
                    }
                    json_single = json.dumps(single_export, ensure_ascii=False, indent=2)
                    st.download_button(
                        label=f"ğŸ“¥ åªåŒ¯å‡ºã€Œ{active_project['name']}ã€",
                        data=json_single,
                        file_name=f"seo_project_{active_project['name']}_{datetime.now().strftime('%Y%m%d')}.json",
                        mime="application/json",
                        use_container_width=True
                    )

        with col2:
            st.markdown("#### ğŸ“¤ åŒ¯å…¥")

            uploaded_file = st.file_uploader("ä¸Šå‚³å°ˆæ¡ˆå‚™ä»½ JSON", type=["json"], key="import_projects")

            if uploaded_file:
                try:
                    imported = json.load(uploaded_file)

                    if "projects" in imported:
                        st.info(f"æª¢æ¸¬åˆ° {len(imported['projects'])} å€‹å°ˆæ¡ˆ")
                        if st.button("ç¢ºèªåŒ¯å…¥æ‰€æœ‰å°ˆæ¡ˆ", type="primary"):
                            for project in imported["projects"]:
                                existing_ids = [p["id"] for p in projects_data["projects"]]
                                if project["id"] not in existing_ids:
                                    projects_data["projects"].append(project)
                                    if project["id"] in imported.get("project_data", {}):
                                        save_project_data(project["id"], imported["project_data"][project["id"]])

                            save_projects(projects_data)
                            st.session_state.projects_data = load_projects()
                            st.success("âœ… åŒ¯å…¥æˆåŠŸï¼")
                            st.rerun()

                    elif "project" in imported:
                        project = imported["project"]
                        st.info(f"æª¢æ¸¬åˆ°å°ˆæ¡ˆï¼š{project['name']}")
                        if st.button("ç¢ºèªåŒ¯å…¥æ­¤å°ˆæ¡ˆ", type="primary"):
                            new_id = f"proj_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}"
                            project["id"] = new_id

                            projects_data["projects"].append(project)
                            save_projects(projects_data)
                            save_project_data(new_id, imported.get("data", {}))

                            st.session_state.projects_data = load_projects()
                            st.success("âœ… åŒ¯å…¥æˆåŠŸï¼")
                            st.rerun()

                except Exception as e:
                    st.error(f"åŒ¯å…¥å¤±æ•—ï¼š{e}")

    st.markdown("---")

# ============ ä¸»åŠŸèƒ½å€ï¼ˆéœ€è¦æœ‰æ´»èºå°ˆæ¡ˆï¼‰============

if active_project:
    current_project_data = load_project_data(active_project["id"])

    # ============ å´é‚Šæ¬„è¨­å®š ============

    with st.sidebar:
        st.markdown("## âš™ï¸ è¨­å®š")

        api_key = st.text_input("ğŸ”‘ Serper API Key", type="password")

        if api_key:
            st.success("âœ… API Key å·²è¨­å®š")
        else:
            st.warning("âš ï¸ è«‹è¼¸å…¥ API Key")

        st.markdown("---")

        # æœå°‹è¨­å®šï¼ˆç·Šæ¹Šç‰ˆï¼‰
        st.markdown("### ğŸ” æœå°‹è¨­å®š")

        col1, col2 = st.columns(2)
        with col1:
            search_region = st.selectbox(
                "åœ°å€",
                options=["hk", "tw", "sg", "my", "us", "uk"],
                format_func=lambda x: {"hk": "ğŸ‡­ğŸ‡° é¦™æ¸¯", "tw": "ğŸ‡¹ğŸ‡¼ å°ç£", "sg": "ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡",
                                       "my": "ğŸ‡²ğŸ‡¾ é¦¬ä¾†è¥¿äº", "us": "ğŸ‡ºğŸ‡¸ ç¾åœ‹", "uk": "ğŸ‡¬ğŸ‡§ è‹±åœ‹"}[x],
                label_visibility="collapsed"
            )

        with col2:
            search_lang = st.selectbox(
                "èªè¨€",
                options=["zh-tw", "zh-cn", "en"],
                format_func=lambda x: {"zh-tw": "ç¹é«”", "zh-cn": "ç®€ä½“", "en": "EN"}[x],
                label_visibility="collapsed"
            )

        max_pages = st.slider("ğŸ“„ çˆ¬å–é æ•¸", 1, 10, 5)

        autocorrect_enabled = st.toggle("ğŸ”¤ è‡ªå‹•æ ¡æ­£", value=False, help="é—œé–‰æ™‚æœƒæœå°‹åŸå§‹é—œéµå­—")
        if not autocorrect_enabled:
            st.caption("ğŸ“ å·²é—œé–‰è‡ªå‹•æ ¡æ­£")

        st.markdown("---")

        st.markdown("### ğŸ  æˆ‘çš„ç¶²ç«™")
        default_my_sites = "\n".join(active_project.get("my_sites", []))
        my_sites_input = st.text_area(
            "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
            value=default_my_sites,
            height=80,
            key="my_sites",
            label_visibility="collapsed"
        )
        my_sites = [s.strip() for s in my_sites_input.split("\n") if s.strip()]

        st.markdown("### ğŸ¯ ç«¶çˆ­å°æ‰‹")
        default_competitors = "\n".join(active_project.get("competitors", []))
        competitors_input = st.text_area(
            "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
            value=default_competitors,
            height=60,
            key="competitors",
            label_visibility="collapsed"
        )
        competitors = [s.strip() for s in competitors_input.split("\n") if s.strip()]

        st.markdown("---")

        st.markdown("### ğŸ¨ é¡¯ç¤ºè¨­å®š")
        warning_threshold = st.number_input(
            "âš ï¸ è­¦å‘Šé–¾å€¼",
            min_value=10,
            max_value=100,
            value=20,
            step=5
        )

        st.markdown("---")

        # é€Ÿåº¦æ¨¡å¼ç§»åˆ°æœ€ä¸‹é¢
        st.markdown("### âš¡ é€Ÿåº¦æ¨¡å¼")
        speed_mode = st.radio(
            "é¸æ“‡æ¨¡å¼",
            options=["stable", "balanced", "fast"],
            format_func=lambda x: {
                "stable": "ğŸ¢ ç©©å®šæ¨¡å¼",
                "balanced": "âš–ï¸ å¹³è¡¡æ¨¡å¼",
                "fast": "ğŸš€ é«˜é€Ÿæ¨¡å¼"
            }[x],
            index=1,
            label_visibility="collapsed"
        )

        if speed_mode == "stable":
            max_concurrent = 1
            delay = 0.5
        elif speed_mode == "balanced":
            max_concurrent = 5
            delay = 0.3
        else:
            max_concurrent = st.slider("æœ€å¤§ä¸¦ç™¼æ•¸", 5, 30, 15)
            delay = 0.1

        st.markdown("---")
        debug_mode = st.checkbox("ğŸ› èª¿è©¦ä¿¡æ¯", value=False)

    # ============ å°èˆªæŒ‰éˆ• ============

    st.markdown("---")

    nav_cols = st.columns(5)
    tab_names = ["ğŸ” æ’åæŸ¥è©¢", "ğŸ·ï¸ é—œéµå­—ç®¡ç†", "ğŸ“Š æ•¸æ“šåˆ†æ", "ğŸ“ˆ æ­·å²è¨˜éŒ„", "âš™ï¸ ç®¡ç†"]

    for i, (col, name) in enumerate(zip(nav_cols, tab_names)):
        with col:
            if st.button(name, key=f"nav_{i}", use_container_width=True,
                         type="primary" if st.session_state.current_tab == i else "secondary"):
                st.session_state.current_tab = i
                st.rerun()

    st.markdown("---")

    # ============ Tab 0: æ’åæŸ¥è©¢ ============

    if st.session_state.current_tab == 0:
        col_left, col_right = st.columns([2, 1])

        with col_left:
            st.markdown("### ğŸ“ è¼¸å…¥é—œéµå­—")

            industry_key = None
            for key, preset in INDUSTRY_PRESETS.items():
                if preset["name"] == active_project.get("industry"):
                    industry_key = key
                    break

            default_keywords = INDUSTRY_PRESETS.get(industry_key, {}).get("keywords_example",
                                                                          "") if industry_key else ""

            keywords_input = st.text_area(
                "æ¯è¡Œä¸€å€‹é—œéµå­—",
                value=st.session_state.get("keywords_input", default_keywords),
                height=200,
                key="keywords_text_area"
            )
            st.session_state["keywords_input"] = keywords_input
            keywords = [k.strip() for k in keywords_input.split("\n") if k.strip()]

        with col_right:
            st.markdown("### ğŸ“‚ é—œéµå­—çµ„ï¼ˆé»æ“Šè¤‡è£½ï¼‰")

            keyword_groups = current_project_data.get("keyword_groups", {})

            if keyword_groups:
                selected_group = st.selectbox(
                    "é¸æ“‡é—œéµå­—çµ„æŸ¥çœ‹",
                    options=["é¸æ“‡..."] + list(keyword_groups.keys()),
                    key="view_group_select"
                )

                if selected_group != "é¸æ“‡...":
                    group_data = keyword_groups[selected_group]
                    group_keywords = group_data.get("keywords", [])
                    group_desc = group_data.get("description", "")

                    st.markdown(f"**{selected_group}** ({len(group_keywords)}å€‹é—œéµå­—)")
                    if group_desc:
                        st.caption(f"ğŸ“ {group_desc}")

                    keywords_text = "\n".join(group_keywords)
                    st.code(keywords_text, language=None)
                    st.caption("ğŸ‘† é»æ“Šå³ä¸Šè§’è¤‡è£½")
            else:
                st.info("ğŸ’¡ é‚„æ²’æœ‰é—œéµå­—çµ„")

            st.markdown("---")
            st.markdown("### ğŸ“‹ æŸ¥è©¢è³‡è¨Š")
            st.markdown(f"**é—œéµå­—æ•¸é‡ï¼š** {len(keywords)}")
            st.markdown(f"**API è«‹æ±‚æ•¸ï¼š** {len(keywords) * max_pages}")

        st.markdown("---")

        col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
        with col_btn2:
            start_tracking = st.button("ğŸš€ é–‹å§‹è¿½è¹¤æ’å", type="primary", use_container_width=True)

        # ============ åŸ·è¡Œæœå°‹ ============

        if start_tracking:
            if not api_key:
                st.error("âŒ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Key")
                st.stop()

            if not keywords:
                st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")
                st.stop()

            all_sites = my_sites + competitors
            if not all_sites:
                st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹è¦è¿½è¹¤çš„ç¶²ç«™")
                st.stop()

            progress_container = st.container()
            with progress_container:
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                with col2:
                    time_display = st.empty()
                with col3:
                    stats_display = st.empty()

            start_time = time.time()

            def update_progress(completed, total, current_keyword):
                progress = completed / total
                progress_bar.progress(progress)
                elapsed = time.time() - start_time
                status_text.text(f"è™•ç†: {current_keyword}")
                time_display.markdown(f"**â±ï¸ {elapsed:.1f}s**")
                stats_display.markdown(f"**{completed}/{total}**")

            if speed_mode == "stable":
                searcher = SequentialSerpSearcher(api_key, search_region, search_lang, delay, autocorrect_enabled)
            elif speed_mode == "balanced":
                searcher = BatchSerpSearcher(api_key, search_region, search_lang, max_concurrent, 0.5, max_concurrent,
                                             autocorrect_enabled)
            else:
                searcher = StableSerpSearcher(api_key, search_region, search_lang, max_concurrent, delay, 3,
                                              autocorrect_enabled)

            serp_results = searcher.search_all(keywords, max_pages, update_progress)
            elapsed_time = time.time() - start_time

            st.session_state.debug_logs = searcher.debug_logs

            if debug_mode and searcher.debug_logs:
                with st.expander("ğŸ› èª¿è©¦æ—¥èªŒ", expanded=True):
                    log_text = "\n".join(searcher.debug_logs[-50:])
                    st.markdown(f'<div class="debug-box">{log_text}</div>', unsafe_allow_html=True)

            all_rankings = find_rankings(serp_results, all_sites)
            progress_bar.progress(1.0)

            success_rate = searcher.success_count / (
                        searcher.success_count + searcher.fail_count) * 100 if (searcher.success_count + searcher.fail_count) > 0 else 0

            if success_rate >= 90:
                st.success(f"âœ… å®Œæˆï¼è€—æ™‚ {elapsed_time:.1f}sï¼ŒæˆåŠŸç‡ {success_rate:.0f}%")
            elif success_rate >= 70:
                st.warning(f"âš ï¸ å®Œæˆï¼Œéƒ¨åˆ†å¤±æ•—ã€‚è€—æ™‚ {elapsed_time:.1f}sï¼ŒæˆåŠŸç‡ {success_rate:.0f}%")
            else:
                st.error(f"âŒ å¤§é‡å¤±æ•—ã€‚æˆåŠŸç‡ {success_rate:.0f}%")

            st.session_state.current_results = {
                "rankings": all_rankings,
                "serp_data": serp_results,
                "timestamp": datetime.now().isoformat(),
                "elapsed_time": elapsed_time,
                "success_rate": success_rate,
                "my_sites": my_sites,
                "competitors": competitors,
                "keywords": keywords
            }

            record = {
                "rankings": all_rankings,
                "my_sites": my_sites,
                "competitors": competitors,
                "region": search_region,
                "keywords": keywords,
                "autocorrect": autocorrect_enabled
            }
            add_record_to_project(active_project["id"], record)

        # ============ é¡¯ç¤ºçµæœ ============

        if st.session_state.current_results:
            st.markdown("---")

            results = st.session_state.current_results
            rankings = results["rankings"]
            result_my_sites = results.get("my_sites", my_sites)
            result_competitors = results.get("competitors", competitors)
            result_keywords = results.get("keywords", [])
            keyword_order_map = {kw: idx for idx, kw in enumerate(result_keywords)}

            history_records = current_project_data.get("records", [])
            previous_rankings = {}
            if len(history_records) >= 2:
                prev_record = history_records[-2]
                for item in prev_record.get("rankings", []):
                    previous_rankings[item.get("keyword")] = item

            st.markdown("## ğŸ“‹ è©³ç´°æ’å")

            st.markdown(f"""
            **åœ–ä¾‹ï¼š** ğŸ”µ æˆ‘çš„ç¶²ç«™ï¼ˆè—è‰²ç³»ï¼‰| ğŸŸ  ç«¶çˆ­å°æ‰‹ï¼ˆæ©™è‰²ç³»ï¼‰| âš ï¸ ç´…è‰² = æ’å > {warning_threshold} | N/A = æœªä¸Šæ¦œ
            """)

            df_display, styled_df = create_styled_ranking_dataframe(
                rankings, result_my_sites, result_competitors, warning_threshold, previous_rankings
            )

            st.dataframe(styled_df, use_container_width=True, height=500)

            def create_excel(rankings_data, serp_data, my_sites_list, competitors_list):
                output = BytesIO()
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df_rankings = pd.DataFrame(rankings_data)
                    df_rankings.to_excel(writer, sheet_name="æ’åç¸½è¦½", index=False)

                    serp_records = []
                    for keyword, results_list in serp_data.items():
                        for result in results_list:
                            serp_records.append({
                                "é—œéµå­—": keyword,
                                "æ’å": result.get("actual_rank"),
                                "æ¨™é¡Œ": result.get("title"),
                                "ç¶²å€": result.get("link"),
                                "æè¿°": result.get("snippet", "")[:200]
                            })
                    if serp_records:
                        pd.DataFrame(serp_records).to_excel(writer, sheet_name="å®Œæ•´SERP", index=False)

                output.seek(0)
                return output

            col_dl1, col_dl2 = st.columns(2)

            with col_dl1:
                excel_file = create_excel(rankings, results.get("serp_data", {}), result_my_sites, result_competitors)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
                    data=excel_file,
                    file_name=f"{active_project['name']}_æ’å_{timestamp}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )

            with col_dl2:
                csv_data = df_display.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ CSV",
                    data=csv_data,
                    file_name=f"{active_project['name']}_æ’å_{timestamp}.csv",
                    mime="text/csv",
                    use_container_width=True
                )

            # ============ æ’åç¸½è¦½ï¼ˆä¸€è¡Œä¸€å€‹é—œéµå­—æ¨£å¼ï¼‰ ============

            st.markdown("---")
            st.markdown("## ğŸ“Š æ’åç¸½è¦½")

            if result_my_sites:
                st.markdown("### ğŸ  æˆ‘çš„ç¶²ç«™")

                for site in result_my_sites:
                    analysis = analyze_site_keywords_detail(rankings, site, warning_threshold, keyword_order_map)

                    with st.expander(f"ğŸ“Š **{site}**", expanded=True):
                        cols = st.columns(6)

                        categories = [
                            ("ğŸ† å‰3å", "top3", "#10B981", len(analysis["top3"])),
                            ("ğŸ“„ é¦–é (4-10)", "top10", "#3B82F6", len(analysis["top10"])),
                            ("ğŸ“‘ ç¬¬2é (11-20)", "top20", "#F59E0B", len(analysis["top20"])),
                            ("ğŸ“‹ ç¬¬3é (21-30)", "top30", "#8B5CF6", len(analysis["top30"])),
                            (f"âš ï¸ >{warning_threshold}å", "warning", "#EF4444", len(analysis["warning"])),
                            ("âŒ æœªä¸Šæ¦œ", "na", "#6B7280", len(analysis["na"]))
                        ]

                        for i, (label, key, color, count) in enumerate(categories):
                            with cols[i]:
                                st.markdown(f"""
                                <div style="text-align: center; padding: 0.5rem; background: white; border-radius: 8px; border-left: 3px solid {color};">
                                    <div style="font-size: 1.5rem; font-weight: bold; color: {color};">{count}</div>
                                    <div style="font-size: 0.75rem; color: #666;">{label}</div>
                                </div>
                                """, unsafe_allow_html=True)

                        st.markdown("---")

                        detail_tabs = st.tabs([
                            f"ğŸ† å‰3å ({len(analysis['top3'])})",
                            f"ğŸ“„ é¦–é  ({len(analysis['top10'])})",
                            f"ğŸ“‘ ç¬¬2é  ({len(analysis['top20'])})",
                            f"ğŸ“‹ ç¬¬3é  ({len(analysis['top30'])})",
                            f"âš ï¸ è­¦å‘Š ({len(analysis['warning'])})",
                            f"âŒ æœªä¸Šæ¦œ ({len(analysis['na'])})"
                        ])

                        with detail_tabs[0]:
                            if analysis["top3"]:
                                display_keyword_list(analysis["top3"], "rank-top3")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨å‰3åçš„é—œéµå­—")

                        with detail_tabs[1]:
                            if analysis["top10"]:
                                display_keyword_list(analysis["top10"], "rank-top10")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨4-10åçš„é—œéµå­—")

                        with detail_tabs[2]:
                            if analysis["top20"]:
                                display_keyword_list(analysis["top20"], "rank-top20")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨11-20åçš„é—œéµå­—")

                        with detail_tabs[3]:
                            if analysis["top30"]:
                                display_keyword_list(analysis["top30"], "rank-top30")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨21-30åçš„é—œéµå­—")

                        with detail_tabs[4]:
                            if analysis["warning"]:
                                st.warning(f"âš ï¸ ä»¥ä¸‹ {len(analysis['warning'])} å€‹é—œéµå­—æ’åè¶…é {warning_threshold}ï¼š")
                                display_keyword_list(analysis["warning"], "rank-warning")
                            else:
                                st.success("æ²’æœ‰éœ€è¦è­¦å‘Šçš„é—œéµå­—ï¼")

                        with detail_tabs[5]:
                            if analysis["na"]:
                                display_keyword_list(analysis["na"], "rank-na", show_rank=False)
                            else:
                                st.success("æ‰€æœ‰é—œéµå­—éƒ½æœ‰æ’åï¼")

            if result_competitors:
                st.markdown("### ğŸ¯ ç«¶çˆ­å°æ‰‹")
            
                for site in result_competitors:
                    analysis = analyze_site_keywords_detail(rankings, site, warning_threshold, keyword_order_map)
            
                    with st.expander(f"ğŸ“Š **{site}**", expanded=False):
                        cols = st.columns(6)
            
                        categories = [
                            ("ğŸ† å‰3å", "top3", "#DC2626", len(analysis["top3"])),
                            ("ğŸ“„ é¦–é (4-10)", "top10", "#F59E0B", len(analysis["top10"])),
                            ("ğŸ“‘ ç¬¬2é (11-20)", "top20", "#6B7280", len(analysis["top20"])),
                            ("ğŸ“‹ ç¬¬3é (21-30)", "top30", "#9CA3AF", len(analysis["top30"])),
                            (f"âš ï¸ >{warning_threshold}å", "warning", "#10B981", len(analysis["warning"])),
                            ("âŒ æœªä¸Šæ¦œ", "na", "#10B981", len(analysis["na"]))
                        ]
            
                        for i, (label, key, color, count) in enumerate(categories):
                            with cols[i]:
                                st.markdown(f"""
                                <div style="text-align: center; padding: 0.5rem; background: white; border-radius: 8px; border-left: 3px solid {color};">
                                    <div style="font-size: 1.5rem; font-weight: bold; color: {color};">{count}</div>
                                    <div style="font-size: 0.75rem; color: #666;">{label}</div>
                                </div>
                                """, unsafe_allow_html=True)
            
                        st.markdown("---")
            
                        # âœ… ä¿®æ”¹é€™è£¡ï¼š6 å€‹ tabs
                        detail_tabs = st.tabs([
                            f"ğŸ† å‰3å ({len(analysis['top3'])})",
                            f"ğŸ“„ é¦–é  ({len(analysis['top10'])})",
                            f"ğŸ“‘ ç¬¬2é  ({len(analysis['top20'])})",
                            f"ğŸ“‹ ç¬¬3é  ({len(analysis['top30'])})",
                            f"âš ï¸ è­¦å‘Š ({len(analysis['warning'])})",
                            f"âŒ æœªä¸Šæ¦œ ({len(analysis['na'])})"
                        ])
            
                        with detail_tabs[0]:
                            if analysis["top3"]:
                                st.warning("âš ï¸ ç«¶çˆ­å°æ‰‹åœ¨é€™äº›é—œéµå­—æ’åå¾ˆé«˜ï¼š")
                                display_keyword_list(analysis["top3"], "rank-warning")
                            else:
                                st.success("ç«¶çˆ­å°æ‰‹æ²’æœ‰æ’åœ¨å‰3åçš„é—œéµå­—")
            
                        with detail_tabs[1]:
                            if analysis["top10"]:
                                st.warning("âš ï¸ ç«¶çˆ­å°æ‰‹åœ¨é¦–é ï¼š")
                                display_keyword_list(analysis["top10"], "rank-top10")
                            else:
                                st.info("ç«¶çˆ­å°æ‰‹æ²’æœ‰æ’åœ¨4-10åçš„é—œéµå­—")
            
                        with detail_tabs[2]:
                            if analysis["top20"]:
                                display_keyword_list(analysis["top20"], "rank-top20")
                            else:
                                st.info("ç«¶çˆ­å°æ‰‹æ²’æœ‰æ’åœ¨11-20åçš„é—œéµå­—")
            
                        with detail_tabs[3]:
                            if analysis["top30"]:
                                display_keyword_list(analysis["top30"], "rank-top30")
                            else:
                                st.info("ç«¶çˆ­å°æ‰‹æ²’æœ‰æ’åœ¨21-30åçš„é—œéµå­—")
            
                        with detail_tabs[4]:
                            if analysis["warning"]:
                                st.success(f"âœ… ç«¶çˆ­å°æ‰‹é€™äº›é—œéµå­—æ’åå·®ï¼ˆ>{warning_threshold}ï¼‰ï¼š")
                                display_keyword_list(analysis["warning"], "rank-warning")
                            else:
                                st.info("ç«¶çˆ­å°æ‰‹æ²’æœ‰æ’åå¾ˆå·®çš„é—œéµå­—")
            
                        with detail_tabs[5]:
                            if analysis["na"]:
                                st.success("âœ… ç«¶çˆ­å°æ‰‹åœ¨é€™äº›é—œéµå­—æ²’æœ‰æ’åï¼š")
                                display_keyword_list(analysis["na"], "rank-na", show_rank=False)
                            else:
                                st.warning("ç«¶çˆ­å°æ‰‹åœ¨æ‰€æœ‰é—œéµå­—éƒ½æœ‰æ’å")

    # ============ Tab 1: é—œéµå­—ç®¡ç† ============

    elif st.session_state.current_tab == 1:
        st.markdown("### ğŸ·ï¸ é—œéµå­—çµ„ç®¡ç†")
        st.caption(f"å°ˆæ¡ˆï¼š{active_project['icon']} {active_project['name']}")

        col_left, col_right = st.columns([1, 1])

        with col_left:
            st.markdown("#### â• æ–°å¢é—œéµå­—çµ„")

            new_group_name = st.text_input("çµ„å", placeholder="ä¾‹å¦‚ï¼šæ ¸å¿ƒé—œéµå­—", key="new_group_name")
            new_group_keywords = st.text_area(
                "é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
                height=200,
                key="new_group_keywords"
            )
            new_group_desc = st.text_input("æè¿°ï¼ˆé¸å¡«ï¼‰", key="new_group_desc")

            if st.button("ğŸ’¾ å„²å­˜é—œéµå­—çµ„", type="primary", use_container_width=True):
                if not new_group_name:
                    st.error("âŒ è«‹è¼¸å…¥çµ„å")
                elif not new_group_keywords.strip():
                    st.error("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")
                else:
                    keywords_list = [k.strip() for k in new_group_keywords.split("\n") if k.strip()]

                    project_data = load_project_data(active_project["id"])
                    if "keyword_groups" not in project_data:
                        project_data["keyword_groups"] = {}

                    project_data["keyword_groups"][new_group_name] = {
                        "keywords": keywords_list,
                        "description": new_group_desc,
                        "created": datetime.now().isoformat(),
                        "updated": datetime.now().isoformat()
                    }
                    save_project_data(active_project["id"], project_data)
                    st.success(f"âœ… å·²å„²å­˜ã€Œ{new_group_name}ã€ï¼ˆ{len(keywords_list)} å€‹é—œéµå­—ï¼‰")
                    st.rerun()

        with col_right:
            st.markdown("#### ğŸ“‹ ç¾æœ‰é—œéµå­—çµ„")

            keyword_groups = current_project_data.get("keyword_groups", {})

            if not keyword_groups:
                st.info("ğŸ’¡ é‚„æ²’æœ‰é—œéµå­—çµ„")
            else:
                for group_name, group_data in keyword_groups.items():
                    group_keywords = group_data.get("keywords", [])
                    group_desc = group_data.get("description", "")

                    with st.expander(f"ğŸ“ {group_name} ({len(group_keywords)}å€‹)", expanded=False):
                        st.markdown(f"**æè¿°ï¼š** {group_desc if group_desc else 'ç„¡'}")

                        keywords_text = "\n".join(group_keywords)
                        st.code(keywords_text, language=None)

                        col1, col2 = st.columns(2)

                        with col2:
                            if st.button("ğŸ—‘ï¸ åˆªé™¤", key=f"delete_{group_name}", use_container_width=True):
                                project_data = load_project_data(active_project["id"])
                                del project_data["keyword_groups"][group_name]
                                save_project_data(active_project["id"], project_data)
                                st.success(f"âœ… å·²åˆªé™¤ã€Œ{group_name}ã€")
                                st.rerun()

    # ============ Tab 2: æ•¸æ“šåˆ†æ ============

    elif st.session_state.current_tab == 2:
        st.markdown("### ğŸ“Š SEO æ•¸æ“šåˆ†æ")
        st.caption(f"å°ˆæ¡ˆï¼š{active_project['icon']} {active_project['name']}")

        history_records = current_project_data.get("records", [])

        if not history_records:
            st.info("ğŸ“Š é‚„æ²’æœ‰æ•¸æ“šï¼Œè«‹å…ˆåŸ·è¡Œæ’åæŸ¥è©¢")
        else:
            analysis_warning_threshold = st.number_input(
                "âš ï¸ åˆ†æè­¦å‘Šé–¾å€¼",
                min_value=10,
                max_value=100,
                value=20,
                step=5,
                key="analysis_warning_threshold"
            )

            st.markdown("---")

            st.markdown("### ğŸ“… é¸æ“‡æŸ¥è©¢è¨˜éŒ„")

            record_options = []
            for i, record in enumerate(reversed(history_records)):
                record_idx = len(history_records) - 1 - i
                display_name = get_record_display_name(record)
                record_options.append((display_name, record_idx))

            selected_record_display = st.selectbox(
                "é¸æ“‡è¦åˆ†æçš„è¨˜éŒ„",
                options=[opt[0] for opt in record_options],
                key="analysis_record_select"
            )

            selected_record_idx = None
            for display_name, idx in record_options:
                if display_name == selected_record_display:
                    selected_record_idx = idx
                    break

            if selected_record_idx is not None:
                selected_record = history_records[selected_record_idx]
                rankings = selected_record.get("rankings", [])
                tracked_my_sites = selected_record.get("my_sites", [])
                tracked_competitors = selected_record.get("competitors", [])
                all_sites_in_record = get_all_sites_from_record(selected_record)
                keyword_order_map = get_keyword_order_map(selected_record)

                st.info(
                    f"ğŸ“Š åˆ†æè¨˜éŒ„: {selected_record.get('date', '')} {selected_record.get('time', '')} | {len(rankings)} å€‹é—œéµå­—")

                st.markdown("---")

                if rankings:
                    # ============ ğŸ” å„ç¶²ç«™è©³ç´°é—œéµå­—åˆ†æ ============

                    st.markdown("### ğŸ” å„ç¶²ç«™è©³ç´°é—œéµå­—")

                    analysis_site = st.selectbox(
                        "é¸æ“‡è¦æŸ¥çœ‹çš„ç¶²ç«™",
                        options=all_sites_in_record,
                        key="detail_analysis_site"
                    )

                    if analysis_site:
                        site_type = "ğŸ  æˆ‘çš„ç¶²ç«™" if analysis_site in tracked_my_sites else "ğŸ¯ ç«¶çˆ­å°æ‰‹"
                        st.markdown(f"**{site_type}ï¼š** `{analysis_site}`")

                        details = analyze_site_keywords_detail(rankings, analysis_site, analysis_warning_threshold,
                                                               keyword_order_map)

                        cols = st.columns(6)
                        categories = [
                            ("ğŸ† å‰3å", "top3", "#10B981"),
                            ("ğŸ“„ é¦–é (4-10)", "top10", "#3B82F6"),
                            ("ğŸ“‘ ç¬¬2é (11-20)", "top20", "#F59E0B"),
                            ("ğŸ“‹ ç¬¬3é (21-30)", "top30", "#8B5CF6"),
                            (f"âš ï¸ >{analysis_warning_threshold}å", "warning", "#EF4444"),
                            ("âŒ æœªä¸Šæ¦œ", "na", "#6B7280")
                        ]

                        for i, (label, key, color) in enumerate(categories):
                            with cols[i]:
                                count = len(details[key])
                                st.markdown(f"""
                                <div class="stat-card" style="border-left-color: {color};">
                                    <div style="font-size: 1.8rem; font-weight: bold; color: {color};">{count}</div>
                                    <div style="font-size: 0.8rem; color: #666;">{label}</div>
                                </div>
                                """, unsafe_allow_html=True)

                        st.markdown("---")

                        detail_tabs = st.tabs([
                            f"ğŸ† å‰3å ({len(details['top3'])})",
                            f"ğŸ“„ é¦–é 4-10 ({len(details['top10'])})",
                            f"ğŸ“‘ ç¬¬2é 11-20 ({len(details['top20'])})",
                            f"ğŸ“‹ ç¬¬3é 21-30 ({len(details['top30'])})",
                            f"âš ï¸ è­¦å‘Š ({len(details['warning'])})",
                            f"âŒ æœªä¸Šæ¦œ ({len(details['na'])})"
                        ])

                        with detail_tabs[0]:
                            if details["top3"]:
                                st.success("ğŸ† é€™äº›é—œéµå­—æ’åå¾ˆå¥½ï¼")
                                display_keyword_list(details["top3"], "rank-top3")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨å‰3åçš„é—œéµå­—")

                        with detail_tabs[1]:
                            if details["top10"]:
                                display_keyword_list(details["top10"], "rank-top10")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨4-10åçš„é—œéµå­—")

                        with detail_tabs[2]:
                            if details["top20"]:
                                display_keyword_list(details["top20"], "rank-top20")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨11-20åçš„é—œéµå­—")

                        with detail_tabs[3]:
                            if details["top30"]:
                                display_keyword_list(details["top30"], "rank-top30")
                            else:
                                st.info("æ²’æœ‰æ’åœ¨21-30åçš„é—œéµå­—")

                        with detail_tabs[4]:
                            if details["warning"]:
                                st.warning(f"âš ï¸ ä»¥ä¸‹ {len(details['warning'])} å€‹é—œéµå­—æ’åè¶…é {analysis_warning_threshold}ï¼š")
                                display_keyword_list(details["warning"], "rank-warning")
                            else:
                                st.success("æ²’æœ‰éœ€è¦è­¦å‘Šçš„é—œéµå­—ï¼")

                        with detail_tabs[5]:
                            if details["na"]:
                                st.error("âŒ é€™äº›é—œéµå­—å®Œå…¨æ²’æœ‰æ’åï¼š")
                                display_keyword_list(details["na"], "rank-na", show_rank=False)
                            else:
                                st.success("æ‰€æœ‰é—œéµå­—éƒ½æœ‰æ’åï¼")

                    st.markdown("---")

                    # ============ ğŸ¥Š é—œéµå­—çˆ­å¥ªåˆ†æ ============

                    st.markdown("### ğŸ¥Š é—œéµå­—çˆ­å¥ªåˆ†æ")

                    col1, col2 = st.columns(2)
                    with col1:
                        site_a = st.selectbox("é¸æ“‡ç¶²ç«™ A", all_sites_in_record, key="compete_site_a")
                    with col2:
                        site_b_options = [s for s in all_sites_in_record if
                                          normalize_domain(s) != normalize_domain(site_a)]
                        site_b = st.selectbox("é¸æ“‡ç¶²ç«™ B",
                                              site_b_options if site_b_options else all_sites_in_record,
                                              key="compete_site_b")

                    if site_a and site_b and normalize_domain(site_a) != normalize_domain(site_b):
                        site_a_type = "ğŸ  æˆ‘çš„ç¶²ç«™" if site_a in tracked_my_sites else "ğŸ¯ ç«¶çˆ­å°æ‰‹"
                        site_b_type = "ğŸ  æˆ‘çš„ç¶²ç«™" if site_b in tracked_my_sites else "ğŸ¯ ç«¶çˆ­å°æ‰‹"

                        st.markdown(f"**æ¯”è¼ƒï¼š** {site_a_type} `{site_a}` **vs** {site_b_type} `{site_b}`")

                        competition = analyze_keyword_competition(rankings, site_a, site_b, keyword_order_map)

                        winning = competition["winning"]
                        losing = competition["losing"]
                        only_a = competition["only_a"]
                        only_b = competition["only_b"]
                        neither = competition["neither"]
                        both_ranked = competition["both_ranked"]

                        site_a_short = site_a[:15] + "..." if len(site_a) > 15 else site_a
                        site_b_short = site_b[:15] + "..." if len(site_b) > 15 else site_b

                        stat_cols = st.columns(5)
                        with stat_cols[0]:
                            st.metric(f"ğŸ† {site_a_short} è´", len(winning))
                        with stat_cols[1]:
                            st.metric(f"ğŸ˜¢ {site_a_short} è¼¸", len(losing))
                        with stat_cols[2]:
                            st.metric(f"âœ… åªæœ‰ A", len(only_a))
                        with stat_cols[3]:
                            st.metric(f"âš ï¸ åªæœ‰ B", len(only_b))
                        with stat_cols[4]:
                            st.metric("âŒ éƒ½æ²’æ’å", len(neither))

                        compete_tabs = st.tabs([
                            f"ğŸ† {site_a_short} è´ ({len(winning)})",
                            f"ğŸ˜¢ {site_a_short} è¼¸ ({len(losing)})",
                            f"âœ… åªæœ‰ {site_a_short} ({len(only_a)})",
                            f"âš ï¸ åªæœ‰ {site_b_short} ({len(only_b)})",
                            f"âŒ éƒ½æ²’æ’å ({len(neither)})",
                            f"ğŸ“Š é›™æ–¹éƒ½æœ‰æ’å ({len(both_ranked)})"
                        ])

                        with compete_tabs[0]:
                            if winning:
                                st.success(f"ğŸ† {site_a} åœ¨é€™äº›é—œéµå­—é ˜å…ˆï¼š")
                                win_data = [{
                                    "é—œéµå­—": item["keyword"],
                                    f"{site_a} æ’å": item["rank_a"],
                                    f"{site_b} æ’å": item["rank_b"],
                                    "å„ªå‹¢": item["rank_b"] - item["rank_a"]
                                } for item in winning]
                                st.dataframe(pd.DataFrame(win_data), use_container_width=True, hide_index=True)
                            else:
                                st.info("æ²’æœ‰é ˜å…ˆçš„é—œéµå­—")

                        with compete_tabs[1]:
                            if losing:
                                st.warning(f"ğŸ˜¢ {site_a} åœ¨é€™äº›é—œéµå­—è½å¾Œï¼š")
                                lose_data = [{
                                    "é—œéµå­—": item["keyword"],
                                    f"{site_a} æ’å": item["rank_a"],
                                    f"{site_b} æ’å": item["rank_b"],
                                    "è½å¾Œ": item["rank_a"] - item["rank_b"]
                                } for item in losing]
                                st.dataframe(pd.DataFrame(lose_data), use_container_width=True, hide_index=True)
                            else:
                                st.success("æ²’æœ‰è½å¾Œçš„é—œéµå­—ï¼")

                        with compete_tabs[2]:
                            if only_a:
                                st.success(f"âœ… åªæœ‰ {site_a} æœ‰æ’åï¼š")
                                only_a_data = [{
                                    "é—œéµå­—": item["keyword"],
                                    f"{site_a} æ’å": item["rank_a"]
                                } for item in only_a]
                                st.dataframe(pd.DataFrame(only_a_data), use_container_width=True, hide_index=True)
                            else:
                                st.info("æ²’æœ‰ç¨ä½”çš„é—œéµå­—")

                        with compete_tabs[3]:
                            if only_b:
                                st.warning(f"âš ï¸ åªæœ‰ {site_b} æœ‰æ’åï¼ˆéœ€è¦åŠ å¼·ï¼‰ï¼š")
                                only_b_data = [{
                                    "é—œéµå­—": item["keyword"],
                                    f"{site_b} æ’å": item["rank_b"]
                                } for item in only_b]
                                st.dataframe(pd.DataFrame(only_b_data), use_container_width=True, hide_index=True)
                            else:
                                st.success("å°æ‰‹æ²’æœ‰ç¨ä½”çš„é—œéµå­—ï¼")

                        with compete_tabs[4]:
                            if neither:
                                st.info("é€™äº›é—œéµå­—é›™æ–¹éƒ½æ²’æœ‰æ’åï¼š")
                                neither_cols = st.columns(3)
                                for idx, item in enumerate(neither):
                                    with neither_cols[idx % 3]:
                                        st.markdown(f"â€¢ {item['keyword']}")
                            else:
                                st.success("æ‰€æœ‰é—œéµå­—è‡³å°‘æœ‰ä¸€æ–¹æœ‰æ’å")

                        with compete_tabs[5]:
                            if both_ranked:
                                both_data = [{
                                    "é—œéµå­—": item["keyword"],
                                    f"{site_a} æ’å": item["rank_a"],
                                    f"{site_b} æ’å": item["rank_b"],
                                    "å·®è·": item["diff"],
                                    "ç‹€æ…‹": "âœ… é ˜å…ˆ" if item["diff"] > 0 else ("ğŸ˜¢ è½å¾Œ" if item["diff"] < 0 else "âš–ï¸ å¹³æ‰‹")
                                } for item in both_ranked]
                                st.dataframe(pd.DataFrame(both_data), use_container_width=True, hide_index=True)
                            else:
                                st.info("æ²’æœ‰é›™æ–¹éƒ½æœ‰æ’åçš„é—œéµå­—")

    # ============ Tab 3: æ­·å²è¨˜éŒ„ ============

    elif st.session_state.current_tab == 3:
        st.markdown("### ğŸ“œ æ­·å²è¨˜éŒ„")
        st.caption(f"å°ˆæ¡ˆï¼š{active_project['icon']} {active_project['name']}")

        history_records = current_project_data.get("records", [])

        if not history_records:
            st.info("ğŸ“Š é‚„æ²’æœ‰æ­·å²è¨˜éŒ„")
        else:
            st.markdown(f"**å…± {len(history_records)} æ¢è¨˜éŒ„**")

            history_warning_threshold = st.number_input(
                "âš ï¸ è­¦å‘Šé–¾å€¼",
                min_value=10,
                max_value=100,
                value=20,
                step=5,
                key="history_warning_threshold"
            )

            st.markdown("---")

            for i, record in enumerate(reversed(history_records)):
                record_idx = len(history_records) - 1 - i
                record_date = record.get("date", "æœªçŸ¥")
                record_time = record.get("time", "")
                record_id = record.get("id", f"record_{i}")
                keyword_count = len(record.get("rankings", []))

                col1, col2, col3 = st.columns([4, 1, 1])

                with col1:
                    expander_title = f"ğŸ“… {record_date} {record_time} | {keyword_count}å€‹é—œéµå­—"

                    with st.expander(expander_title, expanded=False):
                        info_col1, info_col2 = st.columns(2)
                        with info_col1:
                            st.markdown("**ğŸ  ç¶²ç«™ï¼š**")
                            st.write(", ".join(record.get("my_sites", [])))
                        with info_col2:
                            st.markdown("**ğŸ¯ ç«¶çˆ­å°æ‰‹ï¼š**")
                            st.write(", ".join(record.get("competitors", [])))

                        st.markdown("---")

                        record_my_sites = record.get("my_sites", [])
                        record_competitors = record.get("competitors", [])
                        record_rankings = record.get("rankings", [])

                        prev_rankings_dict = {}
                        if record_idx > 0:
                            prev_record = history_records[record_idx - 1]
                            for item in prev_record.get("rankings", []):
                                prev_rankings_dict[item.get("keyword")] = item

                        df_display, styled_df = create_styled_ranking_dataframe(
                            record_rankings,
                            record_my_sites,
                            record_competitors,
                            history_warning_threshold,
                            prev_rankings_dict
                        )

                        st.dataframe(styled_df, use_container_width=True, height=400)

                        st.markdown("---")
                        st.markdown("**ğŸ“Š å„ç¶²ç«™æ’åçµ±è¨ˆï¼š**")

                        all_record_sites = record_my_sites + record_competitors
                        keyword_order = get_keyword_order_map(record)

                        for site in all_record_sites:
                            site_analysis = analyze_site_keywords_detail(record_rankings, site,
                                                                         history_warning_threshold, keyword_order)
                            site_type = "ğŸ " if site in record_my_sites else "ğŸ¯"

                            col_stats = st.columns(7)
                            with col_stats[0]:
                                st.markdown(f"**{site_type} {site[:20]}**")
                            with col_stats[1]:
                                st.markdown(f"ğŸ† {len(site_analysis['top3'])}")
                            with col_stats[2]:
                                st.markdown(f"ğŸ“„ {len(site_analysis['top10'])}")
                            with col_stats[3]:
                                st.markdown(f"ğŸ“‘ {len(site_analysis['top20'])}")
                            with col_stats[4]:
                                st.markdown(f"ğŸ“‹ {len(site_analysis['top30'])}")
                            with col_stats[5]:
                                st.markdown(f"âš ï¸ {len(site_analysis['warning'])}")
                            with col_stats[6]:
                                st.markdown(f"âŒ {len(site_analysis['na'])}")

                with col2:
                    excel_data = export_single_record(record)
                    st.download_button(
                        label="ğŸ“¥ Excel",
                        data=excel_data,
                        file_name=f"{active_project['name']}_{record_date}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"dl_excel_{record_id}_{i}"
                    )

                with col3:
                    if st.button("ğŸ—‘ï¸", key=f"del_record_{record_id}_{i}"):
                        project_data = load_project_data(active_project["id"])
                        project_data["records"] = [r for r in project_data["records"] if r.get("id") != record_id]
                        save_project_data(active_project["id"], project_data)
                        st.success("å·²åˆªé™¤")
                        st.rerun()

    # ============ Tab 4: ç®¡ç† ============

    elif st.session_state.current_tab == 4:
        st.markdown("### âš™ï¸ å°ˆæ¡ˆæ•¸æ“šç®¡ç†")
        st.caption(f"å°ˆæ¡ˆï¼š{active_project['icon']} {active_project['name']}")

        history_records = current_project_data.get("records", [])
        keyword_groups = current_project_data.get("keyword_groups", {})

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown(f"""
            <div class="stat-card">
                <div style="font-size: 2rem; font-weight: bold; color: #667eea;">{len(history_records)}</div>
                <div>ç¸½è¨˜éŒ„æ•¸</div>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            st.markdown(f"""
            <div class="stat-card">
                <div style="font-size: 2rem; font-weight: bold; color: #10B981;">{len(keyword_groups)}</div>
                <div>é—œéµå­—çµ„</div>
            </div>
            """, unsafe_allow_html=True)

        with col3:
            total_keywords = sum(len(g.get("keywords", [])) for g in keyword_groups.values())
            st.markdown(f"""
            <div class="stat-card">
                <div style="font-size: 2rem; font-weight: bold; color: #F59E0B;">{total_keywords}</div>
                <div>ç¸½é—œéµå­—æ•¸</div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("---")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ“¤ åŒ¯å‡ºå°ˆæ¡ˆæ•¸æ“š")

            if history_records or keyword_groups:
                export_data = {
                    "project": active_project,
                    "data": current_project_data
                }
                json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ åŒ¯å‡ºå®Œæ•´å°ˆæ¡ˆ (JSON)",
                    data=json_data,
                    file_name=f"{active_project['name']}_backup_{datetime.now().strftime('%Y%m%d')}.json",
                    mime="application/json",
                    use_container_width=True
                )

                if history_records:
                    all_records_output = BytesIO()
                    with pd.ExcelWriter(all_records_output, engine="openpyxl") as writer:
                        for idx, record in enumerate(history_records):
                            sheet_name = f"{record.get('date', 'unknown')}_{idx}"[:31]
                            df = pd.DataFrame(record.get("rankings", []))
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                    all_records_output.seek(0)

                    st.download_button(
                        label="ğŸ“¥ åŒ¯å‡ºæ‰€æœ‰è¨˜éŒ„ (Excel)",
                        data=all_records_output,
                        file_name=f"{active_project['name']}_all_records_{datetime.now().strftime('%Y%m%d')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )

        with col2:
            st.markdown("#### ğŸ—‘ï¸ æ¸…é™¤æ•¸æ“š")

            if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰è¨˜éŒ„", type="secondary", use_container_width=True):
                st.session_state["confirm_clear_records"] = True

            if st.session_state.get("confirm_clear_records"):
                st.warning("âš ï¸ ç¢ºå®šè¦æ¸…é™¤æ‰€æœ‰æ­·å²è¨˜éŒ„å—ï¼Ÿ")
                col_yes, col_no = st.columns(2)
                with col_yes:
                    if st.button("ç¢ºèªæ¸…é™¤", key="confirm_clear_yes"):
                        project_data = load_project_data(active_project["id"])
                        project_data["records"] = []
                        save_project_data(active_project["id"], project_data)
                        st.session_state.current_results = None
                        del st.session_state["confirm_clear_records"]
                        st.success("âœ… å·²æ¸…é™¤æ‰€æœ‰è¨˜éŒ„")
                        st.rerun()
                with col_no:
                    if st.button("å–æ¶ˆ", key="confirm_clear_no"):
                        del st.session_state["confirm_clear_records"]
                        st.rerun()

            if st.button("ğŸ—‘ï¸ æ¸…é™¤é—œéµå­—çµ„", type="secondary", use_container_width=True):
                st.session_state["confirm_clear_groups"] = True

            if st.session_state.get("confirm_clear_groups"):
                st.warning("âš ï¸ ç¢ºå®šè¦æ¸…é™¤æ‰€æœ‰é—œéµå­—çµ„å—ï¼Ÿ")
                col_yes, col_no = st.columns(2)
                with col_yes:
                    if st.button("ç¢ºèªæ¸…é™¤", key="confirm_clear_groups_yes"):
                        project_data = load_project_data(active_project["id"])
                        project_data["keyword_groups"] = {}
                        save_project_data(active_project["id"], project_data)
                        del st.session_state["confirm_clear_groups"]
                        st.success("âœ… å·²æ¸…é™¤æ‰€æœ‰é—œéµå­—çµ„")
                        st.rerun()
                with col_no:
                    if st.button("å–æ¶ˆ", key="confirm_clear_groups_no"):
                        del st.session_state["confirm_clear_groups"]
                        st.rerun()

        st.markdown("---")

        st.markdown("#### ğŸ“Š å°ˆæ¡ˆè³‡è¨Š")

        st.markdown(f"""
        | é …ç›® | å…§å®¹ |
        |------|------|
        | å°ˆæ¡ˆåç¨± | {active_project['name']} |
        | è¡Œæ¥­ | {active_project['industry']} |
        | å‰µå»ºæ™‚é–“ | {active_project.get('created', 'N/A')[:10]} |
        | æœ€å¾Œæ›´æ–° | {active_project.get('updated', 'N/A')[:10]} |
        | æˆ‘çš„ç¶²ç«™ | {', '.join(active_project.get('my_sites', [])) or 'æœªè¨­å®š'} |
        | ç«¶çˆ­å°æ‰‹ | {', '.join(active_project.get('competitors', [])) or 'æœªè¨­å®š'} |
        """)

# ============ é å°¾ ============

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem;">
    <p>ğŸš€ SEO æ’åè¿½è¹¤å·¥å…· Pro v3.0</p>
    <p style="font-size: 0.8rem;">å¤šå°ˆæ¡ˆç®¡ç† Â· æ™ºèƒ½åˆ†æ Â· ç«¶çˆ­å°æ‰‹è¿½è¹¤</p>
</div>
""", unsafe_allow_html=True)
