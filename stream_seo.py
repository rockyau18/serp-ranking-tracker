import streamlit as st
import requests
import pandas as pd
import time
from datetime import datetime
from io import BytesIO

# ============ é é¢è¨­å®š ============

st.set_page_config(
    page_title="SERP æ’åè¿½è¹¤å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š SERP æ’åè¿½è¹¤å·¥å…·")
st.markdown("è¿½è¹¤ä½ çš„ç¶²ç«™å’Œç«¶çˆ­å°æ‰‹åœ¨ Google é¦™æ¸¯çš„æ’å")

# ============ å´é‚Šæ¬„è¨­å®š ============

st.sidebar.header("âš™ï¸ è¨­å®š")

# API Key
api_key = st.sidebar.text_input(
    "Serper API Key",
    type="password",
    help="åœ¨ serper.dev è¨»å†Šå–å¾—"
)

# çˆ¬å–é æ•¸
max_pages = st.sidebar.slider(
    "çˆ¬å–é æ•¸",
    min_value=1,
    max_value=10,
    value=5,
    help="æ¯é  10 å€‹çµæœ"
)

st.sidebar.markdown(f"ğŸ“„ æ¯å€‹é—œéµå­—å°‡çˆ¬å– **{max_pages * 10}** å€‹çµæœ")

# æˆ‘çš„ç¶²ç«™
st.sidebar.header("ğŸ  æˆ‘çš„ç¶²ç«™")
my_sites_input = st.sidebar.text_area(
    "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
    value="cateringbear.com\ndaynightcatering.com\nbbqmoment.com\ncateringmoment.com",
    height=120
)
my_sites = [s.strip() for s in my_sites_input.split("\n") if s.strip()]

# ç«¶çˆ­å°æ‰‹
st.sidebar.header("ğŸ¯ ç«¶çˆ­å°æ‰‹")
competitors_input = st.sidebar.text_area(
    "æ¯è¡Œä¸€å€‹ç¶²åŸŸ",
    value="kamadelivery.com\ncateringmama.com\ncateraway.com",
    height=100
)
competitors = [s.strip() for s in competitors_input.split("\n") if s.strip()]

# ============ ä¸»è¦å€åŸŸ ============

# é—œéµå­—è¼¸å…¥
st.header("ğŸ” é—œéµå­—")
keywords_input = st.text_area(
    "è¼¸å…¥è¦è¿½è¹¤çš„é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
    value="åˆ°æœƒ\nåˆ°æœƒæ¨ä»‹\næ´¾å°åˆ°æœƒ\nå…¬å¸åˆ°æœƒ",
    height=150
)
keywords = [k.strip() for k in keywords_input.split("\n") if k.strip()]

st.info(f"å…± {len(keywords)} å€‹é—œéµå­—ï¼Œé è¨ˆä½¿ç”¨ {len(keywords) * max_pages} æ¬¡ API èª¿ç”¨")


# ============ å‡½æ•¸å€ ============

def search_serp(keyword, page, api_key):
    url = "https://google.serper.dev/search"

    payload = {
        "q": keyword,
        "gl": "hk",
        "hl": "zh-tw",
        "num": 10,
        "page": page
    }

    headers = {
        "X-API-KEY": api_key,
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, json=payload)
        data = response.json()
        return data.get("organic", [])
    except Exception as e:
        st.error(f"API éŒ¯èª¤: {e}")
        return []


def get_all_results(keyword, max_pages, api_key, progress_bar, status_text):
    all_results = []

    for page in range(1, max_pages + 1):
        status_text.text(f"æŸ¥è©¢ã€Œ{keyword}ã€ç¬¬ {page}/{max_pages} é ...")
        results = search_serp(keyword, page, api_key)

        if not results:
            break

        for result in results:
            original_position = result.get("position", 0)
            actual_rank = (page - 1) * 10 + original_position
            result["actual_rank"] = actual_rank
            result["page"] = page

        all_results.extend(results)
        progress_bar.progress(page / max_pages)
        time.sleep(0.3)

    return all_results


def find_ranking(results, domain):
    for result in results:
        link = result.get("link", "")
        if domain in link:
            return result.get("actual_rank", "N/A")
    return "N/A"


def create_excel(all_rankings, all_serp_data, my_sites, competitors):
    output = BytesIO()

    with pd.ExcelWriter(output, engine="openpyxl") as writer:

        # Sheet 1: æ’åç¸½è¦½
        df_rankings = pd.DataFrame(all_rankings)
        columns = ["keyword"] + my_sites + competitors
        available_columns = [c for c in columns if c in df_rankings.columns]
        df_rankings = df_rankings[available_columns]
        df_rankings.to_excel(writer, sheet_name="æ’åç¸½è¦½", index=False)

        # Sheet 2: å®Œæ•´ SERP æ•¸æ“š
        serp_records = []
        for keyword, results in all_serp_data.items():
            for result in results:
                serp_records.append({
                    "é—œéµå­—": keyword,
                    "æ’å": result.get("actual_rank"),
                    "æ¨™é¡Œ": result.get("title"),
                    "ç¶²å€": result.get("link"),
                    "æè¿°": result.get("snippet", "")[:100]
                })

        df_serp = pd.DataFrame(serp_records)
        df_serp.to_excel(writer, sheet_name="å®Œæ•´SERPæ•¸æ“š", index=False)

        # Sheet 3: æˆ‘çš„ç¶²ç«™è©³æƒ…
        my_site_records = []
        for keyword, results in all_serp_data.items():
            for result in results:
                link = result.get("link", "")
                for site in my_sites:
                    if site in link:
                        my_site_records.append({
                            "é—œéµå­—": keyword,
                            "ç¶²ç«™": site,
                            "æ’å": result.get("actual_rank"),
                            "æ¨™é¡Œ": result.get("title"),
                            "ç¶²å€": link
                        })

        if my_site_records:
            df_my_sites = pd.DataFrame(my_site_records)
            df_my_sites.to_excel(writer, sheet_name="æˆ‘çš„ç¶²ç«™è©³æƒ…", index=False)

        # Sheet 4: ç«¶çˆ­å°æ‰‹è©³æƒ…
        competitor_records = []
        for keyword, results in all_serp_data.items():
            for result in results:
                link = result.get("link", "")
                for site in competitors:
                    if site in link:
                        competitor_records.append({
                            "é—œéµå­—": keyword,
                            "ç¶²ç«™": site,
                            "æ’å": result.get("actual_rank"),
                            "æ¨™é¡Œ": result.get("title"),
                            "ç¶²å€": link
                        })

        if competitor_records:
            df_competitors = pd.DataFrame(competitor_records)
            df_competitors.to_excel(writer, sheet_name="ç«¶çˆ­å°æ‰‹è©³æƒ…", index=False)

    output.seek(0)
    return output


# ============ åŸ·è¡ŒæŒ‰éˆ• ============

st.markdown("---")

if st.button("ğŸš€ é–‹å§‹è¿½è¹¤", type="primary", use_container_width=True):

    # é©—è­‰
    if not api_key:
        st.error("è«‹è¼¸å…¥ API Key")
        st.stop()

    if not keywords:
        st.error("è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")
        st.stop()

    if not my_sites and not competitors:
        st.error("è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹è¦è¿½è¹¤çš„ç¶²ç«™")
        st.stop()

    all_sites = my_sites + competitors
    all_rankings = []
    all_serp_data = {}

    # é€²åº¦é¡¯ç¤º
    overall_progress = st.progress(0)
    status_text = st.empty()

    for i, keyword in enumerate(keywords):
        st.markdown(f"### æ­£åœ¨åˆ†æï¼š{keyword}")

        keyword_progress = st.progress(0)
        keyword_status = st.empty()

        results = get_all_results(keyword, max_pages, api_key, keyword_progress, keyword_status)

        if results:
            rankings = {"keyword": keyword}
            for site in all_sites:
                rank = find_ranking(results, site)
                rankings[site] = rank

            all_rankings.append(rankings)
            all_serp_data[keyword] = results

            keyword_status.text(f"âœ… å®Œæˆï¼å–å¾— {len(results)} å€‹çµæœ")
        else:
            keyword_status.text("âŒ æ²’æœ‰å–å¾—çµæœ")

        overall_progress.progress((i + 1) / len(keywords))

    status_text.text("âœ… å…¨éƒ¨å®Œæˆï¼")

    # é¡¯ç¤ºçµæœ
    st.markdown("---")
    st.header("ğŸ“Š æ’åçµæœ")

    if all_rankings:
        df_rankings = pd.DataFrame(all_rankings)


        # ç”¨é¡è‰²æ¨™ç¤ºæ’å
        def highlight_rank(val):
            if val == "N/A":
                return "background-color: #ffcccc"
            elif isinstance(val, int):
                if val <= 3:
                    return "background-color: #90EE90"  # ç¶ è‰² - å‰3
                elif val <= 10:
                    return "background-color: #FFFFE0"  # é»ƒè‰² - é¦–é 
                elif val <= 20:
                    return "background-color: #FFE4B5"  # æ©™è‰² - ç¬¬2é 
            return ""


        st.dataframe(
            df_rankings.style.applymap(highlight_rank, subset=my_sites + competitors),
            use_container_width=True
        )

        # ä¸‹è¼‰æŒ‰éˆ•
        excel_file = create_excel(all_rankings, all_serp_data, my_sites, competitors)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
            data=excel_file,
            file_name=f"serp_ranking_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )

        # é¡¯ç¤ºè©³ç´°æ•¸æ“š
        with st.expander("ğŸ“‹ æŸ¥çœ‹å®Œæ•´ SERP æ•¸æ“š"):
            for keyword, results in all_serp_data.items():
                st.subheader(f"é—œéµå­—ï¼š{keyword}")
                df = pd.DataFrame([{
                    "æ’å": r.get("actual_rank"),
                    "æ¨™é¡Œ": r.get("title"),
                    "ç¶²å€": r.get("link")
                } for r in results])
                st.dataframe(df, use_container_width=True)

# ============ é å°¾ ============

st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: gray;">
        Made with â¤ï¸ | Powered by Serper API
    </div>
    """,
    unsafe_allow_html=True

)
